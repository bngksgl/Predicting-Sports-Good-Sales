{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from datetime import date, timedelta\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster7=pd.read_csv('clust_7.csv') #cluster numbers\n",
    "cluster12=pd.read_csv('clust_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('integrated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=data[data.month !=1] \n",
    "test_df=data[data.month ==1 ] \n",
    "test_df=test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1166984, 35)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cluster=pd.read_csv('data_clustering_R') #dataset used for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cluster['clust_7']=cluster7['x'] #joining the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cluster=data_cluster[['key','clust_7']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outputting it as csv\n",
    "data_cluster.to_csv('clusters_key_7') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outputting it as csv\n",
    "data_cluster1=data_cluster.copy()\n",
    "data_cluster1['clust_12']=cluster12['x']\n",
    "data_cluster1=data_cluster1[['key','clust_12']]\n",
    "data_cluster1.to_csv('clusters_key_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000 XL ( 158-170 )</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001 L</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003 3 (35-38 )</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003 4 ( 39-42 )</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003 5 ( 43-46 )</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    key  clust_7\n",
       "0  10000 XL ( 158-170 )        1\n",
       "1               10001 L        1\n",
       "2      10003 3 (35-38 )        2\n",
       "3     10003 4 ( 39-42 )        1\n",
       "4     10003 5 ( 43-46 )        1"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>rrp</th>\n",
       "      <th>new size_L</th>\n",
       "      <th>new size_M</th>\n",
       "      <th>new size_S</th>\n",
       "      <th>...</th>\n",
       "      <th>new size_44</th>\n",
       "      <th>new size_43</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>median_temp</th>\n",
       "      <th>company_offer</th>\n",
       "      <th>holiday</th>\n",
       "      <th>sum_unit</th>\n",
       "      <th>price_daily_change</th>\n",
       "      <th>new_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5625</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.3125</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.1875</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7500</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.7500</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           key  weekday  day  month        date     rrp  \\\n",
       "0           0  19671 39 1/3        6    1     10  2017-10-01  190.43   \n",
       "1           1  19671 39 1/3        0    2     10  2017-10-02  190.43   \n",
       "2           2  19671 39 1/3        1    3     10  2017-10-03  190.43   \n",
       "3           3  19671 39 1/3        2    4     10  2017-10-04  190.43   \n",
       "4           4  19671 39 1/3        3    5     10  2017-10-05  190.43   \n",
       "\n",
       "   new size_L  new size_M  new size_S     ...       new size_44  new size_43  \\\n",
       "0           0           0           0     ...                 0            0   \n",
       "1           0           0           0     ...                 0            0   \n",
       "2           0           0           0     ...                 0            0   \n",
       "3           0           0           0     ...                 0            0   \n",
       "4           0           0           0     ...                 0            0   \n",
       "\n",
       "   units  avg_temp  median_temp  company_offer  holiday  sum_unit  \\\n",
       "0    0.0   12.5625        12.50              0        0       0.0   \n",
       "1    0.0   13.3125        13.75              0        0       0.0   \n",
       "2    0.0   12.1875        12.50              0        1       0.0   \n",
       "3    0.0   10.7500        10.75              0        0       0.0   \n",
       "4    1.0   11.7500        11.50              0        0       1.0   \n",
       "\n",
       "   price_daily_change  new_product  \n",
       "0                 0.0            0  \n",
       "1                 0.0            0  \n",
       "2                 0.0            0  \n",
       "3                 0.0            0  \n",
       "4                 0.0            0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code has been taken from the following adress: https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = date(2017, 10, 1)  # start date\n",
    "d2 = date(2017, 12, 31)  # end date\n",
    "d3=date(2018, 1, 31)\n",
    "\n",
    "delta = d2 - d1         # timedelta\n",
    "\n",
    "pre_day=[]\n",
    "for i in range(delta.days + 1):\n",
    "    add=str(d1 + timedelta(days=i))\n",
    "    pre_day.append(add)\n",
    "\n",
    "post_day=[] \n",
    "delta_2 = d3 - d2\n",
    "\n",
    "for i in range(delta_2.days + 1):\n",
    "    add=str(d2 + timedelta(days=i))\n",
    "    post_day.append(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_days_pre = pd.DataFrame({'date':pre_day})\n",
    "df_days_post = pd.DataFrame({'date':post_day})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=train_df[['date','key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1166984, 3)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Windowing with clusters (Lag=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=post_day[1:]\n",
    "col.append('key')\n",
    "all_=train.key.unique()\n",
    "empty_matrix=np.zeros((len(all_),len(col)))\n",
    "data_frame=pd.DataFrame(data=empty_matrix, columns=col)\n",
    "data_frame['key']=all_\n",
    "days=range(1,32)\n",
    "n1=len(days)\n",
    "empty_matrix_2=np.zeros((all_.shape[0],1))\n",
    "data_frame_2=pd.DataFrame(data=empty_matrix_2, columns=['key'])\n",
    "data_frame_2['key']=all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_prev=train.loc[train['date']=='2017-12-31'].sort_values('date')[['key','units']]\n",
    "data_frame_2=data_frame_2.merge(sales_prev, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-31'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>2017-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19671 40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19671 41 1/3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19671 42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19671 42 2/3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  2017-12-31\n",
       "0  19671 39 1/3         0.0\n",
       "1      19671 40         0.0\n",
       "2  19671 41 1/3         1.0\n",
       "3      19671 42         0.0\n",
       "4  19671 42 2/3         0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame=pd.merge(data_frame,data_frame_2,on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2018-01-02</th>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>2018-01-06</th>\n",
       "      <th>2018-01-07</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>2018-01-09</th>\n",
       "      <th>2018-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-01-24</th>\n",
       "      <th>2018-01-25</th>\n",
       "      <th>2018-01-26</th>\n",
       "      <th>2018-01-27</th>\n",
       "      <th>2018-01-28</th>\n",
       "      <th>2018-01-29</th>\n",
       "      <th>2018-01-30</th>\n",
       "      <th>2018-01-31</th>\n",
       "      <th>key</th>\n",
       "      <th>2017-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 41 1/3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42 2/3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05  2018-01-06  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2018-01-07  2018-01-08  2018-01-09  2018-01-10     ...      2018-01-24  \\\n",
       "0         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "1         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "2         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "3         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "4         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "\n",
       "   2018-01-25  2018-01-26  2018-01-27  2018-01-28  2018-01-29  2018-01-30  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2018-01-31           key  2017-12-31  \n",
       "0         0.0  19671 39 1/3         0.0  \n",
       "1         0.0      19671 40         0.0  \n",
       "2         0.0  19671 41 1/3         1.0  \n",
       "3         0.0      19671 42         0.0  \n",
       "4         0.0  19671 42 2/3         0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dataframe=data_frame.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2018-01-02</th>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>2018-01-06</th>\n",
       "      <th>2018-01-07</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>2018-01-09</th>\n",
       "      <th>2018-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-01-25</th>\n",
       "      <th>2018-01-26</th>\n",
       "      <th>2018-01-27</th>\n",
       "      <th>2018-01-28</th>\n",
       "      <th>2018-01-29</th>\n",
       "      <th>2018-01-30</th>\n",
       "      <th>2018-01-31</th>\n",
       "      <th>key</th>\n",
       "      <th>2017-12-31</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 41 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42 2/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05  2018-01-06  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2018-01-07  2018-01-08  2018-01-09  2018-01-10   ...     2018-01-25  \\\n",
       "0         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "1         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "2         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "3         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "4         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "\n",
       "   2018-01-26  2018-01-27  2018-01-28  2018-01-29  2018-01-30  2018-01-31  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "            key  2017-12-31  clust_7  \n",
       "0  19671 39 1/3         0.0        1  \n",
       "1      19671 40         0.0        1  \n",
       "2  19671 41 1/3         1.0        1  \n",
       "3      19671 42         0.0        1  \n",
       "4  19671 42 2/3         0.0        2  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train=train.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>key</th>\n",
       "      <th>units</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           key  units  clust_7\n",
       "0  2017-10-01  19671 39 1/3    0.0        1\n",
       "1  2017-10-02  19671 39 1/3    0.0        1\n",
       "2  2017-10-03  19671 39 1/3    0.0        1\n",
       "3  2017-10-04  19671 39 1/3    0.0        1\n",
       "4  2017-10-05  19671 39 1/3    1.0        1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the clusters\n",
    "def days_1_cluster(c_dataframe,c_train,clusterno,model):\n",
    "    c_train_c1=c_train[c_train['clust_7']==clusterno].drop('clust_7',axis=1)\n",
    "    print(c_train_c1.shape)\n",
    "    print(c_train_c1.key.nunique())\n",
    "    train_comb_pivot=c_train_c1.pivot(index='key', columns='date', values='units')\n",
    "    train_comb_pivot=train_comb_pivot.mean(axis=0) #assign zero sales\n",
    "    train_comb_pivot=pd.DataFrame(train_comb_pivot,columns=['mean_sales'])\n",
    "    train_cluster1=series_to_supervised(train_comb_pivot, n_in=1, n_out=1, dropnan=True)\n",
    "    cluster1=c_dataframe[c_dataframe['clust_7']==clusterno]\n",
    "    cluster1_n=cluster1.drop('clust_7',axis=1).set_index('key').transpose()\n",
    "    cluster1.mean=cluster1_n.mean(axis=1)\n",
    "    cluster1_frame=pd.DataFrame(cluster1.mean, columns=['mean_sales'])\n",
    "    cluster1_frame=cluster1_frame.transpose()\n",
    "    model.fit(train_cluster1[['var1(t-1)']],train_cluster1[['var1(t)']])\n",
    "\n",
    "    days=range(1,32)\n",
    "    n1=len(days)\n",
    "    k=0\n",
    "    day_n=0\n",
    "    while(k<n1):\n",
    "        day=days[day_n]\n",
    "        predicted_date=datetime.date(year=2018,day=day,month=1)\n",
    "        pred_date_before=predicted_date- timedelta(days=1)\n",
    "        delta = predicted_date - pred_date_before\n",
    "        bet_day=[]\n",
    "        for i in range(delta.days):\n",
    "            add=str(pred_date_before + timedelta(days=i))\n",
    "            bet_day.append(add)\n",
    "        pred_date_before=str(pred_date_before)\n",
    "        predicted_date=str(predicted_date)\n",
    "        value_predict=cluster1_frame[bet_day]\n",
    "        y_pred=model.predict(value_predict)\n",
    "        cluster1_frame[predicted_date]=y_pred\n",
    "        k=k+1\n",
    "        day_n=day_n+1\n",
    "    return(cluster1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806078, 3)\n",
      "8858\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster1_frame=days_1_cluster(c_dataframe,c_train,1,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156520, 3)\n",
      "1720\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster2_frame=days_1_cluster(c_dataframe,c_train,2,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25844, 3)\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster3_frame=days_1_cluster(c_dataframe,c_train,3,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 3)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster4_frame=days_1_cluster(c_dataframe,c_train,4,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8463, 3)\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster5_frame=days_1_cluster(c_dataframe,c_train,5,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3640, 3)\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster6_frame=days_1_cluster(c_dataframe,c_train,6,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster7_frame=days_1_cluster(c_dataframe,c_train,7,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performance Measurement\n",
    "import math\n",
    "def cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,date_ass):\n",
    "    test_data['pid']=test_data[\"pid\"].astype(int)\n",
    "    test_data['key']=test_data[\"pid\"].astype(str) +\" \"+ test_data[\"size\"].astype(str) \n",
    "    test_data=test_data[['key','stock','sold_out_date']]\n",
    "    d1 = date(2018, 1, 1)  \n",
    "    d2 = date(2018, 1, 31)  \n",
    "    delta = d2 - d1         \n",
    "    pre_day=[]\n",
    "    for i in range(delta.days + 1):\n",
    "        add=str(d1 + timedelta(days=i))\n",
    "        pre_day.append(add)\n",
    "\n",
    "    all_=test_data.key.unique()\n",
    "    n=len(test_data.key.unique())\n",
    "    i=0\n",
    "    k=0\n",
    "    n1=len(pre_day)\n",
    "    days=[]\n",
    "    ids=[]\n",
    "    while(i<n):\n",
    "        b=all_[i]\n",
    "        k=0\n",
    "        while(k<n1):\n",
    "            a=pre_day[k]\n",
    "            ids.append(b)\n",
    "            days.append(a)\n",
    "            k=k+1\n",
    "        i=i+1\n",
    "    test_days = pd.DataFrame({'date':days,'key':ids})\n",
    "    test_comb=test_days.merge(test_data,on=['key'],how='outer')\n",
    "    test_comb=test_comb.fillna(0)\n",
    "    c_test=test_comb.merge(data_cluster,on='key',how='left')\n",
    "    c_test['clust_7']=c_test['clust_7'].fillna(8)\n",
    "    check=c_test[['key','sold_out_date','clust_7']]\n",
    "    check=check.drop_duplicates()\n",
    "    check['sol_out_pred']=0\n",
    "    i=0\n",
    "    all_=c_test.key.unique()\n",
    "    sold_out=[]\n",
    "    n=len(all_)\n",
    "    while(i<n):\n",
    "        subset_w=c_test.loc[c_test['key']==all_[i]]\n",
    "        check_w=check.loc[check['key']==all_[i]]\n",
    "        stock=subset_w['stock'].values[0]\n",
    "        clust=subset_w['clust_7'].values[0]\n",
    "        n1=len(pre_day)\n",
    "        k=0\n",
    "        while(k<n1): #day based\n",
    "            day=pre_day[k]\n",
    "            that_day_sale=0\n",
    "            if(clust==1):\n",
    "                that_day_sale=cluster1_frame[day].values[0]\n",
    "            if(clust==2):\n",
    "                that_day_sale=cluster2_frame[day].values[0]  \n",
    "            if(clust==3):\n",
    "                that_day_sale=cluster3_frame[day].values[0]\n",
    "            if(clust==4):\n",
    "                that_day_sale=cluster4_frame[day].values[0]\n",
    "            if(clust==5):\n",
    "                that_day_sale=cluster5_frame[day].values[0]\n",
    "            if(clust==6):\n",
    "                that_day_sale=cluster6_frame[day].values[0]\n",
    "            if(clust==7):\n",
    "                that_day_sale=cluster7_frame[day].values[0]\n",
    "            if(clust==8):\n",
    "                sold_out.append(date_ass)\n",
    "                break\n",
    "            stock=stock-that_day_sale\n",
    "            if((stock==0) | (stock<0) ):\n",
    "                sold_out.append(day)\n",
    "                break\n",
    "            if(k==(n1-1)):\n",
    "                sold_out.append(date_ass)\n",
    "            k=k+1\n",
    "        i=i+1\n",
    "        \n",
    "    check['sol_out_pred']=sold_out\n",
    "    check[\"date_sold_out_date\"] = pd.to_datetime(check[\"sold_out_date\"],format=\"%Y/%m/%d\")\n",
    "    check[\"date_sold_out_pred\"] = pd.to_datetime(check[\"sol_out_pred\"],format=\"%Y/%m/%d\")\n",
    "    days_differ=check[\"date_sold_out_date\"]-check[\"date_sold_out_pred\"]\n",
    "    \n",
    "    check['days_differ']=days_differ\n",
    "    check['correct_differ']=abs(check['days_differ'].astype(dt.timedelta).map(lambda x: np.nan if pd.isnull(x) else x.days))\n",
    "\n",
    "    cluster_size=check.clust_7.value_counts()\n",
    "    by_group=check.groupby(['clust_7']).sum()\n",
    "    by_group['clust_size']=cluster_size\n",
    "    by_group['mean']=by_group['correct_differ']/by_group['clust_size']\n",
    "    print(by_group)\n",
    "    \n",
    "    \n",
    "    days=pd.DataFrame(days_differ,columns=['days_differ'])\n",
    "    days['correct_differ']=abs(days['days_differ'].astype(dt.timedelta).map(lambda x: np.nan if pd.isnull(x) else x.days))\n",
    "    summ=sum(days['correct_differ'])\n",
    "    return(math.sqrt(summ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39175        4668  8.392245\n",
      "2.0               12598        1575  7.998730\n",
      "3.0                1795         281  6.387900\n",
      "4.0                  55          11  5.000000\n",
      "5.0                 539          93  5.795699\n",
      "6.0                 232          40  5.800000\n",
      "7.0                   7           4  1.750000\n",
      "8.0               10322        1470  7.021769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "254.4071539874616"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_0.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39542        4668  8.470865\n",
      "2.0               12770        1575  8.107937\n",
      "3.0                1785         281  6.352313\n",
      "4.0                  58          11  5.272727\n",
      "5.0                 478          93  5.139785\n",
      "6.0                 210          40  5.250000\n",
      "7.0                  16           4  4.000000\n",
      "8.0               10299        1470  7.006122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255.26065110000798"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_1.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39418        4668  8.444302\n",
      "2.0               12723        1575  8.078095\n",
      "3.0                1842         281  6.555160\n",
      "4.0                  57          11  5.181818\n",
      "5.0                 508          93  5.462366\n",
      "6.0                 196          40  4.900000\n",
      "7.0                  17           4  4.250000\n",
      "8.0               10273        1470  6.988435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255.01764644824092"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_2.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39333        4668  8.426093\n",
      "2.0               12824        1575  8.142222\n",
      "3.0                1788         281  6.362989\n",
      "4.0                  62          11  5.636364\n",
      "5.0                 467          93  5.021505\n",
      "6.0                 230          40  5.750000\n",
      "7.0                  11           4  2.750000\n",
      "8.0               10214        1470  6.948299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "254.8116951790086"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_3.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39526        4668  8.467438\n",
      "2.0               12859        1575  8.164444\n",
      "3.0                1753         281  6.238434\n",
      "4.0                  57          11  5.181818\n",
      "5.0                 534          93  5.741935\n",
      "6.0                 211          40  5.275000\n",
      "7.0                  18           4  4.500000\n",
      "8.0               10187        1470  6.929932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255.23518566216532"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_4.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Windowing with clusters (Lag=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=post_day[1:]\n",
    "col.append('key')\n",
    "all_=train.key.unique()\n",
    "empty_matrix=np.zeros((len(all_),len(col)))\n",
    "data_frame=pd.DataFrame(data=empty_matrix, columns=col)\n",
    "data_frame['key']=all_\n",
    "days=range(1,32)\n",
    "n1=len(days)\n",
    "empty_matrix_2=np.zeros((all_.shape[0],1))\n",
    "data_frame_2=pd.DataFrame(data=empty_matrix_2, columns=['key'])\n",
    "data_frame_2['key']=all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_prev=train.loc[train['date']=='2017-12-31'].sort_values('date')[['key','units']]\n",
    "sales_prev1=train.loc[train['date']=='2017-12-30'].sort_values('date')[['key','units']]\n",
    "sales_prev2=train.loc[train['date']=='2017-12-29'].sort_values('date')[['key','units']]\n",
    "sales_prev3=train.loc[train['date']=='2017-12-28'].sort_values('date')[['key','units']]\n",
    "sales_prev4=train.loc[train['date']=='2017-12-27'].sort_values('date')[['key','units']]\n",
    "sales_prev5=train.loc[train['date']=='2017-12-26'].sort_values('date')[['key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.merge(sales_prev, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-31'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev1, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-30'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev2, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-29'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev3, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-28'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev4, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-27'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev5, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-26'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.fillna(0)\n",
    "data_frame=pd.merge(data_frame,data_frame_2,on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2018-01-02</th>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>2018-01-06</th>\n",
       "      <th>2018-01-07</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>2018-01-09</th>\n",
       "      <th>2018-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-01-29</th>\n",
       "      <th>2018-01-30</th>\n",
       "      <th>2018-01-31</th>\n",
       "      <th>key</th>\n",
       "      <th>2017-12-31</th>\n",
       "      <th>2017-12-30</th>\n",
       "      <th>2017-12-29</th>\n",
       "      <th>2017-12-28</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2017-12-26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 41 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42 2/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05  2018-01-06  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2018-01-07  2018-01-08  2018-01-09  2018-01-10     ...      2018-01-29  \\\n",
       "0         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "1         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "2         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "3         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "4         0.0         0.0         0.0         0.0     ...             0.0   \n",
       "\n",
       "   2018-01-30  2018-01-31           key  2017-12-31  2017-12-30  2017-12-29  \\\n",
       "0         0.0         0.0  19671 39 1/3         0.0         0.0         0.0   \n",
       "1         0.0         0.0      19671 40         0.0         0.0         0.0   \n",
       "2         0.0         0.0  19671 41 1/3         1.0         0.0         0.0   \n",
       "3         0.0         0.0      19671 42         0.0         0.0         0.0   \n",
       "4         0.0         0.0  19671 42 2/3         0.0         0.0         0.0   \n",
       "\n",
       "   2017-12-28  2017-12-27  2017-12-26  \n",
       "0         0.0         0.0         0.0  \n",
       "1         0.0         0.0         0.0  \n",
       "2         0.0         0.0         0.0  \n",
       "3         0.0         0.0         0.0  \n",
       "4         1.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dataframe=data_frame.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2018-01-02</th>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>2018-01-06</th>\n",
       "      <th>2018-01-07</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>2018-01-09</th>\n",
       "      <th>2018-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-01-30</th>\n",
       "      <th>2018-01-31</th>\n",
       "      <th>key</th>\n",
       "      <th>2017-12-31</th>\n",
       "      <th>2017-12-30</th>\n",
       "      <th>2017-12-29</th>\n",
       "      <th>2017-12-28</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 41 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42 2/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05  2018-01-06  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2018-01-07  2018-01-08  2018-01-09  2018-01-10   ...     2018-01-30  \\\n",
       "0         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "1         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "2         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "3         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "4         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "\n",
       "   2018-01-31           key  2017-12-31  2017-12-30  2017-12-29  2017-12-28  \\\n",
       "0         0.0  19671 39 1/3         0.0         0.0         0.0         0.0   \n",
       "1         0.0      19671 40         0.0         0.0         0.0         0.0   \n",
       "2         0.0  19671 41 1/3         1.0         0.0         0.0         0.0   \n",
       "3         0.0      19671 42         0.0         0.0         0.0         0.0   \n",
       "4         0.0  19671 42 2/3         0.0         0.0         0.0         1.0   \n",
       "\n",
       "   2017-12-27  2017-12-26  clust_7  \n",
       "0         0.0         0.0        1  \n",
       "1         0.0         0.0        1  \n",
       "2         0.0         0.0        1  \n",
       "3         0.0         0.0        1  \n",
       "4         0.0         0.0        2  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train=train.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the clusters\n",
    "def days_5_cluster(c_dataframe,c_train,clusterno,model):\n",
    "    c_train_c1=c_train[c_train['clust_7']==clusterno].drop('clust_7',axis=1)\n",
    "    print(c_train_c1.shape)\n",
    "    print(c_train_c1.key.nunique())\n",
    "    train_comb_pivot=c_train_c1.pivot(index='key', columns='date', values='units')\n",
    "    train_comb_pivot=train_comb_pivot.mean(axis=0) #assign zero sales\n",
    "    train_comb_pivot=pd.DataFrame(train_comb_pivot,columns=['mean_sales'])\n",
    "    train_cluster1=series_to_supervised(train_comb_pivot, n_in=5, n_out=1, dropnan=True)\n",
    "    cluster1=c_dataframe[c_dataframe['clust_7']==clusterno]\n",
    "    cluster1_n=cluster1.drop('clust_7',axis=1).set_index('key').transpose()\n",
    "    cluster1.mean=cluster1_n.mean(axis=1)\n",
    "    cluster1_frame=pd.DataFrame(cluster1.mean, columns=['mean_sales'])\n",
    "    cluster1_frame=cluster1_frame.transpose()\n",
    "    model.fit(train_cluster1[['var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']],train_cluster1[['var1(t)']])\n",
    "\n",
    "    days=range(1,32)\n",
    "    n1=len(days)\n",
    "    k=0\n",
    "    day_n=0\n",
    "    while(k<n1):\n",
    "        day=days[day_n]\n",
    "        predicted_date=datetime.date(year=2018,day=day,month=1)\n",
    "        pred_date_before=predicted_date- timedelta(days=5)\n",
    "        delta = predicted_date - pred_date_before\n",
    "        bet_day=[]\n",
    "        for i in range(delta.days):\n",
    "            add=str(pred_date_before + timedelta(days=i))\n",
    "            bet_day.append(add)\n",
    "        pred_date_before=str(pred_date_before)\n",
    "        predicted_date=str(predicted_date)\n",
    "        value_predict=cluster1_frame[bet_day]\n",
    "        y_pred=model.predict(value_predict)\n",
    "        cluster1_frame[predicted_date]=y_pred\n",
    "        k=k+1\n",
    "        day_n=day_n+1\n",
    "    return(cluster1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2018-01-02</th>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>2018-01-06</th>\n",
       "      <th>2018-01-07</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>2018-01-09</th>\n",
       "      <th>2018-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-01-30</th>\n",
       "      <th>2018-01-31</th>\n",
       "      <th>key</th>\n",
       "      <th>2017-12-31</th>\n",
       "      <th>2017-12-30</th>\n",
       "      <th>2017-12-29</th>\n",
       "      <th>2017-12-28</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 41 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19671 42 2/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05  2018-01-06  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2018-01-07  2018-01-08  2018-01-09  2018-01-10   ...     2018-01-30  \\\n",
       "0         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "1         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "2         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "3         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "4         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "\n",
       "   2018-01-31           key  2017-12-31  2017-12-30  2017-12-29  2017-12-28  \\\n",
       "0         0.0  19671 39 1/3         0.0         0.0         0.0         0.0   \n",
       "1         0.0      19671 40         0.0         0.0         0.0         0.0   \n",
       "2         0.0  19671 41 1/3         1.0         0.0         0.0         0.0   \n",
       "3         0.0      19671 42         0.0         0.0         0.0         0.0   \n",
       "4         0.0  19671 42 2/3         0.0         0.0         0.0         1.0   \n",
       "\n",
       "   2017-12-27  2017-12-26  clust_7  \n",
       "0         0.0         0.0        1  \n",
       "1         0.0         0.0        1  \n",
       "2         0.0         0.0        1  \n",
       "3         0.0         0.0        1  \n",
       "4         0.0         0.0        2  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>key</th>\n",
       "      <th>units</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           key  units  clust_7\n",
       "0  2017-10-01  19671 39 1/3    0.0        1\n",
       "1  2017-10-02  19671 39 1/3    0.0        1\n",
       "2  2017-10-03  19671 39 1/3    0.0        1\n",
       "3  2017-10-04  19671 39 1/3    0.0        1\n",
       "4  2017-10-05  19671 39 1/3    1.0        1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806078, 3)\n",
      "8858\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster1_frame=days_5_cluster(c_dataframe,c_train,1,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156520, 3)\n",
      "1720\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster2_frame=days_5_cluster(c_dataframe,c_train,2,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25844, 3)\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster3_frame=days_5_cluster(c_dataframe,c_train,3,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 3)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster4_frame=days_5_cluster(c_dataframe,c_train,4,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8463, 3)\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster5_frame=days_5_cluster(c_dataframe,c_train,5,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3640, 3)\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster6_frame=days_5_cluster(c_dataframe,c_train,6,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster7_frame=days_5_cluster(c_dataframe,c_train,7,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               40188        4668  8.609254\n",
      "2.0               12600        1575  8.000000\n",
      "3.0                1783         281  6.345196\n",
      "4.0                  55          11  5.000000\n",
      "5.0                 540          93  5.806452\n",
      "6.0                 230          40  5.750000\n",
      "7.0                   7           4  1.750000\n",
      "8.0               10322        1470  7.021769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256.3688748658854"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_0.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               40568        4668  8.690660\n",
      "2.0               12770        1575  8.107937\n",
      "3.0                1782         281  6.341637\n",
      "4.0                  58          11  5.272727\n",
      "5.0                 477          93  5.129032\n",
      "6.0                 210          40  5.250000\n",
      "7.0                  15           4  3.750000\n",
      "8.0               10299        1470  7.006122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "257.25279395956034"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_1.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               40414        4668  8.657669\n",
      "2.0               12718        1575  8.074921\n",
      "3.0                1835         281  6.530249\n",
      "4.0                  58          11  5.272727\n",
      "5.0                 507          93  5.451613\n",
      "6.0                 196          40  4.900000\n",
      "7.0                  17           4  4.250000\n",
      "8.0               10273        1470  6.988435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256.9396816375392"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_2.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               40366        4668  8.647386\n",
      "2.0               12822        1575  8.140952\n",
      "3.0                1780         281  6.334520\n",
      "4.0                  62          11  5.636364\n",
      "5.0                 467          93  5.021505\n",
      "6.0                 230          40  5.750000\n",
      "7.0                  11           4  2.750000\n",
      "8.0               10214        1470  6.948299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256.81121470839236"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_3.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               40557        4668  8.688303\n",
      "2.0               12853        1575  8.160635\n",
      "3.0                1755         281  6.245552\n",
      "4.0                  56          11  5.090909\n",
      "5.0                 535          93  5.752688\n",
      "6.0                 210          40  5.250000\n",
      "7.0                  18           4  4.500000\n",
      "8.0               10187        1470  6.929932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "257.2372445817285"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_4.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Windowing with clusters (Lag=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster7=pd.read_csv('clust_7.csv') #cluster numbers\n",
    "data_cluster=pd.read_csv('data_clustering_R') #dataset used for clustering\n",
    "data_cluster['clust_7']=cluster7['x'] #joining the clusters\n",
    "data_cluster=data_cluster[['key','clust_7']]\n",
    "d1 = date(2017, 10, 1)  # start date\n",
    "d2 = date(2017, 12, 31)  # end date\n",
    "d3=date(2018, 1, 31)\n",
    "\n",
    "delta = d2 - d1         # timedelta\n",
    "\n",
    "pre_day=[]\n",
    "for i in range(delta.days + 1):\n",
    "    add=str(d1 + timedelta(days=i))\n",
    "    pre_day.append(add)\n",
    "\n",
    "post_day=[] \n",
    "delta_2 = d3 - d2\n",
    "\n",
    "for i in range(delta_2.days + 1):\n",
    "    add=str(d2 + timedelta(days=i))\n",
    "    post_day.append(add)\n",
    "df_days_pre = pd.DataFrame({'date':pre_day})\n",
    "df_days_post = pd.DataFrame({'date':post_day})\n",
    "train=train_df[['date','key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1166984, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=post_day[1:]\n",
    "col.append('key')\n",
    "all_=train.key.unique()\n",
    "empty_matrix=np.zeros((len(all_),len(col)))\n",
    "data_frame=pd.DataFrame(data=empty_matrix, columns=col)\n",
    "data_frame['key']=all_\n",
    "days=range(1,32)\n",
    "n1=len(days)\n",
    "empty_matrix_2=np.zeros((all_.shape[0],1))\n",
    "data_frame_2=pd.DataFrame(data=empty_matrix_2, columns=['key'])\n",
    "data_frame_2['key']=all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_prev=train.loc[train['date']=='2017-12-31'].sort_values('date')[['key','units']]\n",
    "sales_prev1=train.loc[train['date']=='2017-12-30'].sort_values('date')[['key','units']]\n",
    "sales_prev2=train.loc[train['date']=='2017-12-29'].sort_values('date')[['key','units']]\n",
    "sales_prev3=train.loc[train['date']=='2017-12-28'].sort_values('date')[['key','units']]\n",
    "sales_prev4=train.loc[train['date']=='2017-12-27'].sort_values('date')[['key','units']]\n",
    "sales_prev5=train.loc[train['date']=='2017-12-26'].sort_values('date')[['key','units']]\n",
    "sales_prev6=train.loc[train['date']=='2017-12-25'].sort_values('date')[['key','units']]\n",
    "sales_prev7=train.loc[train['date']=='2017-12-24'].sort_values('date')[['key','units']]\n",
    "sales_prev8=train.loc[train['date']=='2017-12-23'].sort_values('date')[['key','units']]\n",
    "sales_prev9=train.loc[train['date']=='2017-12-22'].sort_values('date')[['key','units']]\n",
    "sales_prev10=train.loc[train['date']=='2017-12-21'].sort_values('date')[['key','units']]\n",
    "sales_prev11=train.loc[train['date']=='2017-12-20'].sort_values('date')[['key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.merge(sales_prev, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-31'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev1, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-30'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev2, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-29'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev3, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-28'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev4, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-27'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev5, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-26'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev6, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-25'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev7, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-24'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev8, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-23'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev9, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-22'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev10, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-21'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev11, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-20'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.fillna(0)\n",
    "data_frame=pd.merge(data_frame,data_frame_2,on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train=train.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>key</th>\n",
       "      <th>units</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           key  units  clust_7\n",
       "0  2017-10-01  19671 39 1/3    0.0        1\n",
       "1  2017-10-02  19671 39 1/3    0.0        1\n",
       "2  2017-10-03  19671 39 1/3    0.0        1\n",
       "3  2017-10-04  19671 39 1/3    0.0        1\n",
       "4  2017-10-05  19671 39 1/3    1.0        1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dataframe=data_frame.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the clusters\n",
    "def days_10_cluster(c_dataframe,c_train,clusterno,model):\n",
    "    c_train_c1=c_train[c_train['clust_7']==clusterno].drop('clust_7',axis=1)\n",
    "    print(c_train_c1.shape)\n",
    "    print(c_train_c1.key.nunique())\n",
    "    train_comb_pivot=c_train_c1.pivot(index='key', columns='date', values='units')\n",
    "    train_comb_pivot=train_comb_pivot.mean(axis=0) #assign zero sales\n",
    "    train_comb_pivot=pd.DataFrame(train_comb_pivot,columns=['mean_sales'])\n",
    "    train_cluster1=series_to_supervised(train_comb_pivot, n_in=10, n_out=1, dropnan=True)\n",
    "    cluster1=c_dataframe[c_dataframe['clust_7']==clusterno]\n",
    "    cluster1_n=cluster1.drop('clust_7',axis=1).set_index('key').transpose()\n",
    "    cluster1.mean=cluster1_n.mean(axis=1)\n",
    "    cluster1_frame=pd.DataFrame(cluster1.mean, columns=['mean_sales'])\n",
    "    cluster1_frame=cluster1_frame.transpose()\n",
    "    model.fit(train_cluster1[['var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
    "                          'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)']],train_cluster1[['var1(t)']])\n",
    "    days=range(1,32)\n",
    "    n1=len(days)\n",
    "    k=0\n",
    "    day_n=0\n",
    "    while(k<n1):\n",
    "        day=days[day_n]\n",
    "        predicted_date=datetime.date(year=2018,day=day,month=1)\n",
    "        pred_date_before=predicted_date- timedelta(days=10)\n",
    "        delta = predicted_date - pred_date_before\n",
    "        bet_day=[]\n",
    "        for i in range(delta.days):\n",
    "            add=str(pred_date_before + timedelta(days=i))\n",
    "            bet_day.append(add)\n",
    "        pred_date_before=str(pred_date_before)\n",
    "        predicted_date=str(predicted_date)\n",
    "        value_predict=cluster1_frame[bet_day]\n",
    "        y_pred=model.predict(value_predict)\n",
    "        cluster1_frame[predicted_date]=y_pred\n",
    "        k=k+1\n",
    "        day_n=day_n+1\n",
    "    return(cluster1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806078, 3)\n",
      "8858\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster1_frame=days_10_cluster(c_dataframe,c_train,1,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156520, 3)\n",
      "1720\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster2_frame=days_10_cluster(c_dataframe,c_train,2,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25844, 3)\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster3_frame=days_10_cluster(c_dataframe,c_train,3,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 3)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster4_frame=days_10_cluster(c_dataframe,c_train,4,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8463, 3)\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster5_frame=days_10_cluster(c_dataframe,c_train,5,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3640, 3)\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster6_frame=days_10_cluster(c_dataframe,c_train,6,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster7_frame=days_10_cluster(c_dataframe,c_train,7,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39175        4668  8.392245\n",
      "2.0               12634        1575  8.021587\n",
      "3.0                1783         281  6.345196\n",
      "4.0                  52          11  4.727273\n",
      "5.0                 537          93  5.774194\n",
      "6.0                 241          40  6.025000\n",
      "7.0                   8           4  2.000000\n",
      "8.0               10322        1470  7.021769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "254.46414285710276"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_0.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39542        4668  8.470865\n",
      "2.0               12803        1575  8.128889\n",
      "3.0                1782         281  6.341637\n",
      "4.0                  56          11  5.090909\n",
      "5.0                 473          93  5.086022\n",
      "6.0                 210          40  5.250000\n",
      "7.0                  16           4  4.000000\n",
      "8.0               10299        1470  7.006122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255.30569911382707"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_1.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39418        4668  8.444302\n",
      "2.0               12754        1575  8.097778\n",
      "3.0                1835         281  6.530249\n",
      "4.0                  54          11  4.909091\n",
      "5.0                 502          93  5.397849\n",
      "6.0                 202          40  5.050000\n",
      "7.0                  17           4  4.250000\n",
      "8.0               10273        1470  6.988435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255.05881674625562"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_2.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39333        4668  8.426093\n",
      "2.0               12857        1575  8.163175\n",
      "3.0                1780         281  6.334520\n",
      "4.0                  60          11  5.454545\n",
      "5.0                 464          93  4.989247\n",
      "6.0                 232          40  5.800000\n",
      "7.0                  13           4  3.250000\n",
      "8.0               10214        1470  6.948299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "254.85878442776894"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_3.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39526        4668  8.467438\n",
      "2.0               12876        1575  8.175238\n",
      "3.0                1755         281  6.245552\n",
      "4.0                  53          11  4.818182\n",
      "5.0                 528          93  5.677419\n",
      "6.0                 211          40  5.275000\n",
      "7.0                  20           4  5.000000\n",
      "8.0               10187        1470  6.929932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255.2567335057001"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_4.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Windowing with clusters (Lag=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster7=pd.read_csv('clust_7.csv') #cluster number\n",
    "data_cluster=pd.read_csv('data_clustering_R') #dataset used for clustering\n",
    "data_cluster['clust_7']=cluster7['x'] #joining the clusters\n",
    "data_cluster=data_cluster[['key','clust_7']]\n",
    "d1 = date(2017, 10, 1)  # start date\n",
    "d2 = date(2017, 12, 31)  # end date\n",
    "d3=date(2018, 1, 31)\n",
    "delta = d2 - d1         # timedelta\n",
    "\n",
    "pre_day=[]\n",
    "for i in range(delta.days + 1):\n",
    "    add=str(d1 + timedelta(days=i))\n",
    "    pre_day.append(add)\n",
    "\n",
    "post_day=[] \n",
    "delta_2 = d3 - d2\n",
    "\n",
    "for i in range(delta_2.days + 1):\n",
    "    add=str(d2 + timedelta(days=i))\n",
    "    post_day.append(add)\n",
    "df_days_pre = pd.DataFrame({'date':pre_day})\n",
    "df_days_post = pd.DataFrame({'date':post_day})\n",
    "train=train_df[['date','key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=post_day[1:]\n",
    "col.append('key')\n",
    "all_=train.key.unique()\n",
    "empty_matrix=np.zeros((len(all_),len(col)))\n",
    "data_frame=pd.DataFrame(data=empty_matrix, columns=col)\n",
    "data_frame['key']=all_\n",
    "days=range(1,32)\n",
    "n1=len(days)\n",
    "empty_matrix_2=np.zeros((all_.shape[0],1))\n",
    "data_frame_2=pd.DataFrame(data=empty_matrix_2, columns=['key'])\n",
    "data_frame_2['key']=all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_prev=train.loc[train['date']=='2017-12-31'].sort_values('date')[['key','units']]\n",
    "sales_prev1=train.loc[train['date']=='2017-12-30'].sort_values('date')[['key','units']]\n",
    "sales_prev2=train.loc[train['date']=='2017-12-29'].sort_values('date')[['key','units']]\n",
    "sales_prev3=train.loc[train['date']=='2017-12-28'].sort_values('date')[['key','units']]\n",
    "sales_prev4=train.loc[train['date']=='2017-12-27'].sort_values('date')[['key','units']]\n",
    "sales_prev5=train.loc[train['date']=='2017-12-26'].sort_values('date')[['key','units']]\n",
    "sales_prev6=train.loc[train['date']=='2017-12-25'].sort_values('date')[['key','units']]\n",
    "sales_prev7=train.loc[train['date']=='2017-12-24'].sort_values('date')[['key','units']]\n",
    "sales_prev8=train.loc[train['date']=='2017-12-23'].sort_values('date')[['key','units']]\n",
    "sales_prev9=train.loc[train['date']=='2017-12-22'].sort_values('date')[['key','units']]\n",
    "sales_prev10=train.loc[train['date']=='2017-12-21'].sort_values('date')[['key','units']]\n",
    "sales_prev11=train.loc[train['date']=='2017-12-20'].sort_values('date')[['key','units']]\n",
    "sales_prev12=train.loc[train['date']=='2017-12-19'].sort_values('date')[['key','units']]\n",
    "sales_prev13=train.loc[train['date']=='2017-12-18'].sort_values('date')[['key','units']]\n",
    "sales_prev14=train.loc[train['date']=='2017-12-17'].sort_values('date')[['key','units']]\n",
    "sales_prev15=train.loc[train['date']=='2017-12-16'].sort_values('date')[['key','units']]\n",
    "sales_prev16=train.loc[train['date']=='2017-12-15'].sort_values('date')[['key','units']]\n",
    "sales_prev17=train.loc[train['date']=='2017-12-14'].sort_values('date')[['key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.merge(sales_prev, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-31'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev1, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-30'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev2, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-29'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev3, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-28'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev4, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-27'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev5, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-26'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev6, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-25'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev7, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-24'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev8, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-23'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev9, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-22'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev10, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-21'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev11, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-20'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev12, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-19'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev13, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-18'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev14, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-17'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev15, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-16'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev16, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-15'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev17, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-14'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.fillna(0)\n",
    "data_frame=pd.merge(data_frame,data_frame_2,on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train=train.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dataframe=data_frame.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the clusters\n",
    "def days_15_cluster(c_dataframe,c_train,clusterno,model):\n",
    "    c_train_c1=c_train[c_train['clust_7']==clusterno].drop('clust_7',axis=1)\n",
    "    print(c_train_c1.shape)\n",
    "    print(c_train_c1.key.nunique())\n",
    "    train_comb_pivot=c_train_c1.pivot(index='key', columns='date', values='units')\n",
    "    train_comb_pivot=train_comb_pivot.mean(axis=0) #assign zero sales\n",
    "    train_comb_pivot=pd.DataFrame(train_comb_pivot,columns=['mean_sales'])\n",
    "    train_cluster1=series_to_supervised(train_comb_pivot, n_in=15, n_out=1, dropnan=True)\n",
    "    cluster1=c_dataframe[c_dataframe['clust_7']==clusterno]\n",
    "    cluster1_n=cluster1.drop('clust_7',axis=1).set_index('key').transpose()\n",
    "    cluster1.mean=cluster1_n.mean(axis=1)\n",
    "    cluster1_frame=pd.DataFrame(cluster1.mean, columns=['mean_sales'])\n",
    "    cluster1_frame=cluster1_frame.transpose()\n",
    "    model.fit(train_cluster1[['var1(t-15)', 'var1(t-14)', 'var1(t-13)', 'var1(t-12)',\n",
    "       'var1(t-11)', 'var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)',\n",
    "       'var1(t-6)', 'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)',\n",
    "       'var1(t-1)']],train_cluster1[['var1(t)']])\n",
    "    \n",
    "    days=range(1,32)\n",
    "    n1=len(days)\n",
    "    k=0\n",
    "    day_n=0\n",
    "    while(k<n1):\n",
    "        day=days[day_n]\n",
    "        predicted_date=datetime.date(year=2018,day=day,month=1)\n",
    "        pred_date_before=predicted_date- timedelta(days=15)\n",
    "        delta = predicted_date - pred_date_before\n",
    "        bet_day=[]\n",
    "        for i in range(delta.days):\n",
    "            add=str(pred_date_before + timedelta(days=i))\n",
    "            bet_day.append(add)\n",
    "        pred_date_before=str(pred_date_before)\n",
    "        predicted_date=str(predicted_date)\n",
    "        value_predict=cluster1_frame[bet_day]\n",
    "        y_pred=model.predict(value_predict)\n",
    "        cluster1_frame[predicted_date]=y_pred\n",
    "        k=k+1\n",
    "        day_n=day_n+1\n",
    "    return(cluster1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806078, 3)\n",
      "8858\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster1_frame=days_15_cluster(c_dataframe,c_train,1,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156520, 3)\n",
      "1720\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster2_frame=days_15_cluster(c_dataframe,c_train,2,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25844, 3)\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster3_frame=days_15_cluster(c_dataframe,c_train,3,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 3)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster4_frame=days_15_cluster(c_dataframe,c_train,4,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8463, 3)\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster5_frame=days_15_cluster(c_dataframe,c_train,5,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3640, 3)\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster6_frame=days_15_cluster(c_dataframe,c_train,6,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster7_frame=days_15_cluster(c_dataframe,c_train,7,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39175        4668  8.392245\n",
      "2.0               12607        1575  8.004444\n",
      "3.0                1775         281  6.316726\n",
      "4.0                  54          11  4.909091\n",
      "5.0                 532          93  5.720430\n",
      "6.0                 237          40  5.925000\n",
      "7.0                  10           4  2.500000\n",
      "8.0               10322        1470  7.021769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "254.3855341799136"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_0.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39542        4668  8.470865\n",
      "2.0               12710        1575  8.069841\n",
      "3.0                1749         281  6.224199\n",
      "4.0                  55          11  5.000000\n",
      "5.0                 466          93  5.010753\n",
      "6.0                 210          40  5.250000\n",
      "7.0                  20           4  5.000000\n",
      "8.0               10299        1470  7.006122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255.05097529709624"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_1.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39418        4668  8.444302\n",
      "2.0               12709        1575  8.069206\n",
      "3.0                1833         281  6.523132\n",
      "4.0                  53          11  4.818182\n",
      "5.0                 500          93  5.376344\n",
      "6.0                 202          40  5.050000\n",
      "7.0                  21           4  5.250000\n",
      "8.0               10273        1470  6.988435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "254.9686255208668"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_2.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39333        4668  8.426093\n",
      "2.0               12775        1575  8.111111\n",
      "3.0                1764         281  6.277580\n",
      "4.0                  58          11  5.272727\n",
      "5.0                 454          93  4.881720\n",
      "6.0                 227          40  5.675000\n",
      "7.0                  16           4  4.000000\n",
      "8.0               10214        1470  6.948299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "254.6389600984107"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_3.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39526        4668  8.467438\n",
      "2.0               12792        1575  8.121905\n",
      "3.0                1740         281  6.192171\n",
      "4.0                  53          11  4.818182\n",
      "5.0                 524          93  5.634409\n",
      "6.0                 216          40  5.400000\n",
      "7.0                  22           4  5.500000\n",
      "8.0               10187        1470  6.929932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255.068618218706"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_4.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Windowing with clusters (Lag=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster7=pd.read_csv('clust_7.csv') #cluster number\n",
    "data_cluster=pd.read_csv('data_clustering_R') #dataset used for clustering\n",
    "data_cluster['clust_7']=cluster7['x'] #joining the clusters\n",
    "data_cluster=data_cluster[['key','clust_7']]\n",
    "d1 = date(2017, 10, 1)  # start date\n",
    "d2 = date(2017, 12, 31)  # end date\n",
    "d3=date(2018, 1, 31)\n",
    "delta = d2 - d1         # timedelta\n",
    "\n",
    "pre_day=[]\n",
    "for i in range(delta.days + 1):\n",
    "    add=str(d1 + timedelta(days=i))\n",
    "    pre_day.append(add)\n",
    "\n",
    "post_day=[] \n",
    "delta_2 = d3 - d2\n",
    "\n",
    "for i in range(delta_2.days + 1):\n",
    "    add=str(d2 + timedelta(days=i))\n",
    "    post_day.append(add)\n",
    "df_days_pre = pd.DataFrame({'date':pre_day})\n",
    "df_days_post = pd.DataFrame({'date':post_day})\n",
    "train=train_df[['date','key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=post_day[1:]\n",
    "col.append('key')\n",
    "all_=train.key.unique()\n",
    "empty_matrix=np.zeros((len(all_),len(col)))\n",
    "data_frame=pd.DataFrame(data=empty_matrix, columns=col)\n",
    "data_frame['key']=all_\n",
    "days=range(1,32)\n",
    "n1=len(days)\n",
    "empty_matrix_2=np.zeros((all_.shape[0],1))\n",
    "data_frame_2=pd.DataFrame(data=empty_matrix_2, columns=['key'])\n",
    "data_frame_2['key']=all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_prev=train.loc[train['date']=='2017-12-31'].sort_values('date')[['key','units']]\n",
    "sales_prev1=train.loc[train['date']=='2017-12-30'].sort_values('date')[['key','units']]\n",
    "sales_prev2=train.loc[train['date']=='2017-12-29'].sort_values('date')[['key','units']]\n",
    "sales_prev3=train.loc[train['date']=='2017-12-28'].sort_values('date')[['key','units']]\n",
    "sales_prev4=train.loc[train['date']=='2017-12-27'].sort_values('date')[['key','units']]\n",
    "sales_prev5=train.loc[train['date']=='2017-12-26'].sort_values('date')[['key','units']]\n",
    "sales_prev6=train.loc[train['date']=='2017-12-25'].sort_values('date')[['key','units']]\n",
    "sales_prev7=train.loc[train['date']=='2017-12-24'].sort_values('date')[['key','units']]\n",
    "sales_prev8=train.loc[train['date']=='2017-12-23'].sort_values('date')[['key','units']] \n",
    "sales_prev9=train.loc[train['date']=='2017-12-22'].sort_values('date')[['key','units']]\n",
    "sales_prev10=train.loc[train['date']=='2017-12-21'].sort_values('date')[['key','units']]\n",
    "sales_prev11=train.loc[train['date']=='2017-12-20'].sort_values('date')[['key','units']]\n",
    "sales_prev12=train.loc[train['date']=='2017-12-19'].sort_values('date')[['key','units']]\n",
    "sales_prev13=train.loc[train['date']=='2017-12-18'].sort_values('date')[['key','units']]\n",
    "sales_prev14=train.loc[train['date']=='2017-12-17'].sort_values('date')[['key','units']]\n",
    "sales_prev15=train.loc[train['date']=='2017-12-16'].sort_values('date')[['key','units']]\n",
    "sales_prev16=train.loc[train['date']=='2017-12-15'].sort_values('date')[['key','units']]\n",
    "sales_prev17=train.loc[train['date']=='2017-12-14'].sort_values('date')[['key','units']]\n",
    "sales_prev18=train.loc[train['date']=='2017-12-13'].sort_values('date')[['key','units']]\n",
    "sales_prev19=train.loc[train['date']=='2017-12-12'].sort_values('date')[['key','units']]\n",
    "sales_prev20=train.loc[train['date']=='2017-12-11'].sort_values('date')[['key','units']]\n",
    "sales_prev21=train.loc[train['date']=='2017-12-10'].sort_values('date')[['key','units']]\n",
    "sales_prev22=train.loc[train['date']=='2017-12-09'].sort_values('date')[['key','units']]\n",
    "data_frame_2=data_frame_2.merge(sales_prev, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-31'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev1, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-30'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev2, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-29'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev3, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-28'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev4, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-27'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev5, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-26'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev6, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-25'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev7, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-24'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev8, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-23'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev9, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-22'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev10, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-21'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev11, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-20'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev12, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-19'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev13, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-18'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev14, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-17'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev15, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-16'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev16, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-15'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev17, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-14'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev18, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-13'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev19, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-12'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev20, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-11'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev21, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-10'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev22, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-09'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.fillna(0)\n",
    "data_frame=pd.merge(data_frame,data_frame_2,on='key')\n",
    "c_train=train.merge(data_cluster,on='key',how='inner')\n",
    "c_dataframe=data_frame.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>key</th>\n",
       "      <th>units</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           key  units  clust_7\n",
       "0  2017-10-01  19671 39 1/3    0.0        1\n",
       "1  2017-10-02  19671 39 1/3    0.0        1\n",
       "2  2017-10-03  19671 39 1/3    0.0        1\n",
       "3  2017-10-04  19671 39 1/3    0.0        1\n",
       "4  2017-10-05  19671 39 1/3    1.0        1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the clusters\n",
    "def days_20_cluster(c_dataframe,c_train,clusterno,model):\n",
    "    c_train_c1=c_train[c_train['clust_7']==clusterno].drop('clust_7',axis=1)\n",
    "    print(c_train_c1.shape)\n",
    "    print(c_train_c1.key.nunique())\n",
    "    train_comb_pivot=c_train_c1.pivot(index='key', columns='date', values='units')\n",
    "    train_comb_pivot=train_comb_pivot.mean(axis=0) #assign zero sales\n",
    "    train_comb_pivot=pd.DataFrame(train_comb_pivot,columns=['mean_sales'])\n",
    "    train_cluster1=series_to_supervised(train_comb_pivot, n_in=20, n_out=1, dropnan=True)\n",
    "    cluster1=c_dataframe[c_dataframe['clust_7']==clusterno]\n",
    "    cluster1_n=cluster1.drop('clust_7',axis=1).set_index('key').transpose()\n",
    "    cluster1.mean=cluster1_n.mean(axis=1)\n",
    "    cluster1_frame=pd.DataFrame(cluster1.mean, columns=['mean_sales'])\n",
    "    cluster1_frame=cluster1_frame.transpose()\n",
    "    model.fit(train_cluster1[['var1(t-20)', 'var1(t-19)', 'var1(t-18)', 'var1(t-17)',\n",
    "       'var1(t-16)', 'var1(t-15)', 'var1(t-14)', 'var1(t-13)',\n",
    "       'var1(t-12)', 'var1(t-11)', 'var1(t-10)', 'var1(t-9)', 'var1(t-8)',\n",
    "       'var1(t-7)', 'var1(t-6)', 'var1(t-5)', 'var1(t-4)', 'var1(t-3)',\n",
    "       'var1(t-2)', 'var1(t-1)']],train_cluster1[['var1(t)']])\n",
    "    \n",
    "    days=range(1,32)\n",
    "    n1=len(days)\n",
    "    k=0\n",
    "    day_n=0\n",
    "    while(k<n1):\n",
    "        day=days[day_n]\n",
    "        predicted_date=datetime.date(year=2018,day=day,month=1)\n",
    "        pred_date_before=predicted_date- timedelta(days=20)\n",
    "        delta = predicted_date - pred_date_before\n",
    "        bet_day=[]\n",
    "        for i in range(delta.days):\n",
    "            add=str(pred_date_before + timedelta(days=i))\n",
    "            bet_day.append(add)\n",
    "        pred_date_before=str(pred_date_before)\n",
    "        predicted_date=str(predicted_date)\n",
    "        value_predict=cluster1_frame[bet_day]\n",
    "        y_pred=model.predict(value_predict)\n",
    "        cluster1_frame[predicted_date]=y_pred\n",
    "        k=k+1\n",
    "        day_n=day_n+1\n",
    "    return(cluster1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806078, 3)\n",
      "8858\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster1_frame=days_20_cluster(c_dataframe,c_train,1,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156520, 3)\n",
      "1720\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster2_frame=days_20_cluster(c_dataframe,c_train,2,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25844, 3)\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster3_frame=days_20_cluster(c_dataframe,c_train,3,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 3)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster4_frame=days_20_cluster(c_dataframe,c_train,4,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8463, 3)\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster5_frame=days_20_cluster(c_dataframe,c_train,5,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3640, 3)\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster6_frame=days_20_cluster(c_dataframe,c_train,6,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster7_frame=days_20_cluster(c_dataframe,c_train,7,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               37577        4668  8.049914\n",
      "2.0               12941        1575  8.216508\n",
      "3.0                1879         281  6.686833\n",
      "4.0                  63          11  5.727273\n",
      "5.0                 566          93  6.086022\n",
      "6.0                 230          40  5.750000\n",
      "7.0                   9           4  2.250000\n",
      "8.0               10322        1470  7.021769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.16462876462273"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_0.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               37916        4668  8.122536\n",
      "2.0               13071        1575  8.299048\n",
      "3.0                1829         281  6.508897\n",
      "4.0                  66          11  6.000000\n",
      "5.0                 497          93  5.344086\n",
      "6.0                 210          40  5.250000\n",
      "7.0                  17           4  4.250000\n",
      "8.0               10299        1470  7.006122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.79438284898657"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_1.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               37816        4668  8.101114\n",
      "2.0               13091        1575  8.311746\n",
      "3.0                1915         281  6.814947\n",
      "4.0                  65          11  5.909091\n",
      "5.0                 520          93  5.591398\n",
      "6.0                 199          40  4.975000\n",
      "7.0                  19           4  4.750000\n",
      "8.0               10273        1470  6.988435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.78053722547548"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_2.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               37679        4668  8.071765\n",
      "2.0               13160        1575  8.355556\n",
      "3.0                1869         281  6.651246\n",
      "4.0                  69          11  6.272727\n",
      "5.0                 481          93  5.172043\n",
      "6.0                 228          40  5.700000\n",
      "7.0                  14           4  3.500000\n",
      "8.0               10214        1470  6.948299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.4163227685563"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_3.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               37882        4668  8.115253\n",
      "2.0               13193        1575  8.376508\n",
      "3.0                1831         281  6.516014\n",
      "4.0                  64          11  5.818182\n",
      "5.0                 554          93  5.956989\n",
      "6.0                 209          40  5.225000\n",
      "7.0                  21           4  5.250000\n",
      "8.0               10187        1470  6.929932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.86557693762904"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_4.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Windowing with clusters (Lag=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster7=pd.read_csv('clust_7.csv') #cluster number\n",
    "data_cluster=pd.read_csv('data_clustering_R') #dataset used for clustering\n",
    "data_cluster['clust_7']=cluster7['x'] #joining the clusters\n",
    "data_cluster=data_cluster[['key','clust_7']]\n",
    "d1 = date(2017, 10, 1)  # start date\n",
    "d2 = date(2017, 12, 31)  # end date\n",
    "d3=date(2018, 1, 31)\n",
    "delta = d2 - d1         # timedelta\n",
    "\n",
    "pre_day=[]\n",
    "for i in range(delta.days + 1):\n",
    "    add=str(d1 + timedelta(days=i))\n",
    "    pre_day.append(add)\n",
    "\n",
    "post_day=[] \n",
    "delta_2 = d3 - d2\n",
    "\n",
    "for i in range(delta_2.days + 1):\n",
    "    add=str(d2 + timedelta(days=i))\n",
    "    post_day.append(add)\n",
    "df_days_pre = pd.DataFrame({'date':pre_day})\n",
    "df_days_post = pd.DataFrame({'date':post_day})\n",
    "train=train_df[['date','key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=post_day[1:]\n",
    "col.append('key')\n",
    "all_=train.key.unique()\n",
    "empty_matrix=np.zeros((len(all_),len(col)))\n",
    "data_frame=pd.DataFrame(data=empty_matrix, columns=col)\n",
    "data_frame['key']=all_\n",
    "days=range(1,32)\n",
    "n1=len(days)\n",
    "empty_matrix_2=np.zeros((all_.shape[0],1))\n",
    "data_frame_2=pd.DataFrame(data=empty_matrix_2, columns=['key'])\n",
    "data_frame_2['key']=all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_prev=train.loc[train['date']=='2017-12-31'].sort_values('date')[['key','units']]\n",
    "sales_prev1=train.loc[train['date']=='2017-12-30'].sort_values('date')[['key','units']]\n",
    "sales_prev2=train.loc[train['date']=='2017-12-29'].sort_values('date')[['key','units']]\n",
    "sales_prev3=train.loc[train['date']=='2017-12-28'].sort_values('date')[['key','units']]\n",
    "sales_prev4=train.loc[train['date']=='2017-12-27'].sort_values('date')[['key','units']]\n",
    "sales_prev5=train.loc[train['date']=='2017-12-26'].sort_values('date')[['key','units']]\n",
    "sales_prev6=train.loc[train['date']=='2017-12-25'].sort_values('date')[['key','units']]\n",
    "sales_prev7=train.loc[train['date']=='2017-12-24'].sort_values('date')[['key','units']]\n",
    "sales_prev8=train.loc[train['date']=='2017-12-23'].sort_values('date')[['key','units']] \n",
    "sales_prev9=train.loc[train['date']=='2017-12-22'].sort_values('date')[['key','units']]\n",
    "sales_prev10=train.loc[train['date']=='2017-12-21'].sort_values('date')[['key','units']]\n",
    "sales_prev11=train.loc[train['date']=='2017-12-20'].sort_values('date')[['key','units']]\n",
    "sales_prev12=train.loc[train['date']=='2017-12-19'].sort_values('date')[['key','units']]\n",
    "sales_prev13=train.loc[train['date']=='2017-12-18'].sort_values('date')[['key','units']]\n",
    "sales_prev14=train.loc[train['date']=='2017-12-17'].sort_values('date')[['key','units']]\n",
    "sales_prev15=train.loc[train['date']=='2017-12-16'].sort_values('date')[['key','units']]\n",
    "sales_prev16=train.loc[train['date']=='2017-12-15'].sort_values('date')[['key','units']]\n",
    "sales_prev17=train.loc[train['date']=='2017-12-14'].sort_values('date')[['key','units']]\n",
    "sales_prev18=train.loc[train['date']=='2017-12-13'].sort_values('date')[['key','units']]\n",
    "sales_prev19=train.loc[train['date']=='2017-12-12'].sort_values('date')[['key','units']]\n",
    "sales_prev20=train.loc[train['date']=='2017-12-11'].sort_values('date')[['key','units']]\n",
    "sales_prev21=train.loc[train['date']=='2017-12-10'].sort_values('date')[['key','units']]\n",
    "sales_prev22=train.loc[train['date']=='2017-12-09'].sort_values('date')[['key','units']]\n",
    "sales_prev23=train.loc[train['date']=='2017-12-08'].sort_values('date')[['key','units']]\n",
    "sales_prev24=train.loc[train['date']=='2017-12-07'].sort_values('date')[['key','units']]\n",
    "sales_prev25=train.loc[train['date']=='2017-12-06'].sort_values('date')[['key','units']]\n",
    "sales_prev26=train.loc[train['date']=='2017-12-05'].sort_values('date')[['key','units']]\n",
    "sales_prev27=train.loc[train['date']=='2017-12-04'].sort_values('date')[['key','units']]\n",
    "sales_prev28=train.loc[train['date']=='2017-12-03'].sort_values('date')[['key','units']]\n",
    "sales_prev29=train.loc[train['date']=='2017-12-02'].sort_values('date')[['key','units']]\n",
    "sales_prev30=train.loc[train['date']=='2017-12-01'].sort_values('date')[['key','units']]\n",
    "data_frame_2=data_frame_2.merge(sales_prev, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-31'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev1, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-30'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev2, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-29'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev3, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-28'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev4, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-27'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev5, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-26'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev6, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-25'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev7, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-24'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev8, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-23'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev9, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-22'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev10, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-21'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev11, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-20'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev12, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-19'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev13, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-18'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev14, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-17'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev15, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-16'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev16, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-15'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev17, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-14'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev18, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-13'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev19, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-12'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev20, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-11'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev21, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-10'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev22, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-09'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev23, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-08'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev24, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-07'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev25, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-06'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev26, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-05'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev27, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-04'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev28, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-03'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev29, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-02'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev30, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-01'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.fillna(0)\n",
    "data_frame=pd.merge(data_frame,data_frame_2,on='key')\n",
    "c_train=train.merge(data_cluster,on='key',how='inner')\n",
    "c_dataframe=data_frame.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the clusters\n",
    "def days_30_cluster(c_dataframe,c_train,clusterno,model):\n",
    "    c_train_c1=c_train[c_train['clust_7']==clusterno].drop('clust_7',axis=1)\n",
    "    print(c_train_c1.shape)\n",
    "    print(c_train_c1.key.nunique())\n",
    "    train_comb_pivot=c_train_c1.pivot(index='key', columns='date', values='units')\n",
    "    train_comb_pivot=train_comb_pivot.mean(axis=0) #assign zero sales\n",
    "    train_comb_pivot=pd.DataFrame(train_comb_pivot,columns=['mean_sales'])\n",
    "    train_cluster1=series_to_supervised(train_comb_pivot, n_in=30, n_out=1, dropnan=True)\n",
    "    cluster1=c_dataframe[c_dataframe['clust_7']==clusterno]\n",
    "    cluster1_n=cluster1.drop('clust_7',axis=1).set_index('key').transpose()\n",
    "    cluster1.mean=cluster1_n.mean(axis=1)\n",
    "    cluster1_frame=pd.DataFrame(cluster1.mean, columns=['mean_sales'])\n",
    "    cluster1_frame=cluster1_frame.transpose()\n",
    "    model.fit(train_cluster1[['var1(t-30)', 'var1(t-29)', 'var1(t-28)', 'var1(t-27)',\n",
    "       'var1(t-26)', 'var1(t-25)', 'var1(t-24)', 'var1(t-23)',\n",
    "       'var1(t-22)', 'var1(t-21)', 'var1(t-20)', 'var1(t-19)',\n",
    "       'var1(t-18)', 'var1(t-17)', 'var1(t-16)', 'var1(t-15)',\n",
    "       'var1(t-14)', 'var1(t-13)', 'var1(t-12)', 'var1(t-11)',\n",
    "       'var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
    "       'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)']],train_cluster1[['var1(t)']])\n",
    "    \n",
    "    days=range(1,32)\n",
    "    n1=len(days)\n",
    "    k=0\n",
    "    day_n=0\n",
    "    while(k<n1):\n",
    "        day=days[day_n]\n",
    "        predicted_date=datetime.date(year=2018,day=day,month=1)\n",
    "        pred_date_before=predicted_date- timedelta(days=30)\n",
    "        delta = predicted_date - pred_date_before\n",
    "        bet_day=[]\n",
    "        for i in range(delta.days):\n",
    "            add=str(pred_date_before + timedelta(days=i))\n",
    "            bet_day.append(add)\n",
    "        pred_date_before=str(pred_date_before)\n",
    "        predicted_date=str(predicted_date)\n",
    "        value_predict=cluster1_frame[bet_day]\n",
    "        y_pred=model.predict(value_predict)\n",
    "        cluster1_frame[predicted_date]=y_pred\n",
    "        k=k+1\n",
    "        day_n=day_n+1\n",
    "    return(cluster1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806078, 3)\n",
      "8858\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster1_frame=days_30_cluster(c_dataframe,c_train,1,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156520, 3)\n",
      "1720\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster2_frame=days_30_cluster(c_dataframe,c_train,2,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25844, 3)\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster3_frame=days_30_cluster(c_dataframe,c_train,3,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 3)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster4_frame=days_30_cluster(c_dataframe,c_train,4,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8463, 3)\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster5_frame=days_30_cluster(c_dataframe,c_train,5,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3640, 3)\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster6_frame=days_30_cluster(c_dataframe,c_train,6,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster7_frame=days_30_cluster(c_dataframe,c_train,7,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39175        4668  8.392245\n",
      "2.0               11513        1575  7.309841\n",
      "3.0                1797         281  6.395018\n",
      "4.0                  67          11  6.090909\n",
      "5.0                 571          93  6.139785\n",
      "6.0                 234          40  5.850000\n",
      "7.0                   9           4  2.250000\n",
      "8.0               10322        1470  7.021769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.36481529722008"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_0.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39542        4668  8.470865\n",
      "2.0               11601        1575  7.365714\n",
      "3.0                1714         281  6.099644\n",
      "4.0                  68          11  6.181818\n",
      "5.0                 500          93  5.376344\n",
      "6.0                 221          40  5.525000\n",
      "7.0                  17           4  4.250000\n",
      "8.0               10299        1470  7.006122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.90709756746645"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_1.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39418        4668  8.444302\n",
      "2.0               11715        1575  7.438095\n",
      "3.0                1814         281  6.455516\n",
      "4.0                  66          11  6.000000\n",
      "5.0                 524          93  5.634409\n",
      "6.0                 213          40  5.325000\n",
      "7.0                  19           4  4.750000\n",
      "8.0               10273        1470  6.988435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "253.06520898772317"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_2.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39333        4668  8.426093\n",
      "2.0               11736        1575  7.451429\n",
      "3.0                1750         281  6.227758\n",
      "4.0                  72          11  6.545455\n",
      "5.0                 480          93  5.161290\n",
      "6.0                 228          40  5.700000\n",
      "7.0                  13           4  3.250000\n",
      "8.0               10214        1470  6.948299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.6380810566768"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_3.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size      mean\n",
      "clust_7                                      \n",
      "1.0               39526        4668  8.467438\n",
      "2.0               11756        1575  7.464127\n",
      "3.0                1697         281  6.039146\n",
      "4.0                  66          11  6.000000\n",
      "5.0                 555          93  5.967742\n",
      "6.0                 222          40  5.550000\n",
      "7.0                  17           4  4.250000\n",
      "8.0               10187        1470  6.929932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "253.03359460751452"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_4.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Windowing with Clusters (Lag=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster7=pd.read_csv('clust_7.csv') #cluster number\n",
    "data_cluster=pd.read_csv('data_clustering_R') #dataset used for clustering\n",
    "data_cluster['clust_7']=cluster7['x'] #joining the clusters\n",
    "data_cluster=data_cluster[['key','clust_7']]\n",
    "d1 = date(2017, 10, 1)  # start date\n",
    "d2 = date(2017, 12, 31)  # end date\n",
    "d3=date(2018, 1, 31)\n",
    "delta = d2 - d1         # timedelta\n",
    "\n",
    "pre_day=[]\n",
    "for i in range(delta.days + 1):\n",
    "    add=str(d1 + timedelta(days=i))\n",
    "    pre_day.append(add)\n",
    "\n",
    "post_day=[] \n",
    "delta_2 = d3 - d2\n",
    "\n",
    "for i in range(delta_2.days + 1):\n",
    "    add=str(d2 + timedelta(days=i))\n",
    "    post_day.append(add)\n",
    "df_days_pre = pd.DataFrame({'date':pre_day})\n",
    "df_days_post = pd.DataFrame({'date':post_day})\n",
    "train=train_df[['date','key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=post_day[1:]\n",
    "col.append('key')\n",
    "all_=train.key.unique()\n",
    "empty_matrix=np.zeros((len(all_),len(col)))\n",
    "data_frame=pd.DataFrame(data=empty_matrix, columns=col)\n",
    "data_frame['key']=all_\n",
    "days=range(1,32)\n",
    "n1=len(days)\n",
    "empty_matrix_2=np.zeros((all_.shape[0],1))\n",
    "data_frame_2=pd.DataFrame(data=empty_matrix_2, columns=['key'])\n",
    "data_frame_2['key']=all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_prev=train.loc[train['date']=='2017-12-31'].sort_values('date')[['key','units']]\n",
    "sales_prev1=train.loc[train['date']=='2017-12-30'].sort_values('date')[['key','units']]\n",
    "sales_prev2=train.loc[train['date']=='2017-12-29'].sort_values('date')[['key','units']]\n",
    "sales_prev3=train.loc[train['date']=='2017-12-28'].sort_values('date')[['key','units']]\n",
    "sales_prev4=train.loc[train['date']=='2017-12-27'].sort_values('date')[['key','units']]\n",
    "sales_prev5=train.loc[train['date']=='2017-12-26'].sort_values('date')[['key','units']]\n",
    "sales_prev6=train.loc[train['date']=='2017-12-25'].sort_values('date')[['key','units']]\n",
    "sales_prev7=train.loc[train['date']=='2017-12-24'].sort_values('date')[['key','units']]\n",
    "sales_prev8=train.loc[train['date']=='2017-12-23'].sort_values('date')[['key','units']] \n",
    "sales_prev9=train.loc[train['date']=='2017-12-22'].sort_values('date')[['key','units']]\n",
    "sales_prev10=train.loc[train['date']=='2017-12-21'].sort_values('date')[['key','units']]\n",
    "sales_prev11=train.loc[train['date']=='2017-12-20'].sort_values('date')[['key','units']]\n",
    "sales_prev12=train.loc[train['date']=='2017-12-19'].sort_values('date')[['key','units']]\n",
    "sales_prev13=train.loc[train['date']=='2017-12-18'].sort_values('date')[['key','units']]\n",
    "sales_prev14=train.loc[train['date']=='2017-12-17'].sort_values('date')[['key','units']]\n",
    "sales_prev15=train.loc[train['date']=='2017-12-16'].sort_values('date')[['key','units']]\n",
    "sales_prev16=train.loc[train['date']=='2017-12-15'].sort_values('date')[['key','units']]\n",
    "sales_prev17=train.loc[train['date']=='2017-12-14'].sort_values('date')[['key','units']]\n",
    "sales_prev18=train.loc[train['date']=='2017-12-13'].sort_values('date')[['key','units']]\n",
    "sales_prev19=train.loc[train['date']=='2017-12-12'].sort_values('date')[['key','units']]\n",
    "sales_prev20=train.loc[train['date']=='2017-12-11'].sort_values('date')[['key','units']]\n",
    "sales_prev21=train.loc[train['date']=='2017-12-10'].sort_values('date')[['key','units']]\n",
    "sales_prev22=train.loc[train['date']=='2017-12-09'].sort_values('date')[['key','units']]\n",
    "sales_prev23=train.loc[train['date']=='2017-12-08'].sort_values('date')[['key','units']]\n",
    "sales_prev24=train.loc[train['date']=='2017-12-07'].sort_values('date')[['key','units']]\n",
    "sales_prev25=train.loc[train['date']=='2017-12-06'].sort_values('date')[['key','units']]\n",
    "sales_prev26=train.loc[train['date']=='2017-12-05'].sort_values('date')[['key','units']]\n",
    "sales_prev27=train.loc[train['date']=='2017-12-04'].sort_values('date')[['key','units']]\n",
    "sales_prev28=train.loc[train['date']=='2017-12-03'].sort_values('date')[['key','units']]\n",
    "sales_prev29=train.loc[train['date']=='2017-12-02'].sort_values('date')[['key','units']]\n",
    "sales_prev30=train.loc[train['date']=='2017-12-01'].sort_values('date')[['key','units']]\n",
    "sales_prev31=train.loc[train['date']=='2017-11-30'].sort_values('date')[['key','units']]\n",
    "sales_prev32=train.loc[train['date']=='2017-11-29'].sort_values('date')[['key','units']]\n",
    "sales_prev33=train.loc[train['date']=='2017-11-28'].sort_values('date')[['key','units']]\n",
    "sales_prev34=train.loc[train['date']=='2017-11-27'].sort_values('date')[['key','units']]\n",
    "sales_prev35=train.loc[train['date']=='2017-11-26'].sort_values('date')[['key','units']]\n",
    "sales_prev36=train.loc[train['date']=='2017-11-25'].sort_values('date')[['key','units']]\n",
    "sales_prev37=train.loc[train['date']=='2017-11-24'].sort_values('date')[['key','units']]\n",
    "sales_prev38=train.loc[train['date']=='2017-11-23'].sort_values('date')[['key','units']]\n",
    "sales_prev39=train.loc[train['date']=='2017-11-22'].sort_values('date')[['key','units']]\n",
    "sales_prev40=train.loc[train['date']=='2017-11-21'].sort_values('date')[['key','units']]\n",
    "sales_prev41=train.loc[train['date']=='2017-11-20'].sort_values('date')[['key','units']]\n",
    "data_frame_2=data_frame_2.merge(sales_prev, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-31'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev1, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-30'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev2, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-29'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev3, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-28'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev4, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-27'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev5, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-26'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev6, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-25'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev7, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-24'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev8, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-23'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev9, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-22'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev10, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-21'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev11, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-20'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev12, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-19'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev13, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-18'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev14, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-17'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev15, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-16'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev16, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-15'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev17, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-14'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev18, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-13'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev19, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-12'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev20, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-11'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev21, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-10'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev22, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-09'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev23, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-08'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev24, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-07'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev25, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-06'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev26, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-05'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev27, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-04'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev28, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-03'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev29, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-02'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev30, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-01'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev31, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-30'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev32, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-29'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev33, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-28'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev34, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-27'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev35, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-26'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev36, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-25'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev37, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-24'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev38, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-23'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev39, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-22'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev40, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-21'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev41, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-11-20'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.fillna(0)\n",
    "data_frame=pd.merge(data_frame,data_frame_2,on='key')\n",
    "c_train=train.merge(data_cluster,on='key',how='inner')\n",
    "c_dataframe=data_frame.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the clusters\n",
    "def days_40_cluster(c_dataframe,c_train,clusterno,model):\n",
    "    c_train_c1=c_train[c_train['clust_7']==clusterno].drop('clust_7',axis=1)\n",
    "    print(c_train_c1.shape)\n",
    "    print(c_train_c1.key.nunique())\n",
    "    train_comb_pivot=c_train_c1.pivot(index='key', columns='date', values='units')\n",
    "    train_comb_pivot=train_comb_pivot.mean(axis=0) #assign zero sales\n",
    "    train_comb_pivot=pd.DataFrame(train_comb_pivot,columns=['mean_sales'])\n",
    "    train_cluster1=series_to_supervised(train_comb_pivot, n_in=40, n_out=1, dropnan=True)\n",
    "    cluster1=c_dataframe[c_dataframe['clust_7']==clusterno]\n",
    "    cluster1_n=cluster1.drop('clust_7',axis=1).set_index('key').transpose()\n",
    "    cluster1.mean=cluster1_n.mean(axis=1)\n",
    "    cluster1_frame=pd.DataFrame(cluster1.mean, columns=['mean_sales'])\n",
    "    cluster1_frame=cluster1_frame.transpose()\n",
    "    model.fit(train_cluster1[['var1(t-40)','var1(t-39)','var1(t-38)','var1(t-37)','var1(t-36)','var1(t-35)','var1(t-34)',\n",
    "                         'var1(t-33)','var1(t-32)','var1(t-31)','var1(t-30)', 'var1(t-29)', 'var1(t-28)', 'var1(t-27)',\n",
    "       'var1(t-26)', 'var1(t-25)', 'var1(t-24)', 'var1(t-23)',\n",
    "       'var1(t-22)', 'var1(t-21)', 'var1(t-20)', 'var1(t-19)',\n",
    "       'var1(t-18)', 'var1(t-17)', 'var1(t-16)', 'var1(t-15)',\n",
    "       'var1(t-14)', 'var1(t-13)', 'var1(t-12)', 'var1(t-11)',\n",
    "       'var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
    "           'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)']],train_cluster1[['var1(t)']])\n",
    "    \n",
    "    days=range(1,32)\n",
    "    n1=len(days)\n",
    "    k=0\n",
    "    day_n=0\n",
    "    while(k<n1):\n",
    "        day=days[day_n]\n",
    "        predicted_date=datetime.date(year=2018,day=day,month=1)\n",
    "        pred_date_before=predicted_date- timedelta(days=40)\n",
    "        delta = predicted_date - pred_date_before\n",
    "        bet_day=[]\n",
    "        for i in range(delta.days):\n",
    "            add=str(pred_date_before + timedelta(days=i))\n",
    "            bet_day.append(add)\n",
    "        pred_date_before=str(pred_date_before)\n",
    "        predicted_date=str(predicted_date)\n",
    "        value_predict=cluster1_frame[bet_day]\n",
    "        y_pred=model.predict(value_predict)\n",
    "        cluster1_frame[predicted_date]=y_pred\n",
    "        k=k+1\n",
    "        day_n=day_n+1\n",
    "    return(cluster1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806078, 3)\n",
      "8858\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster1_frame=days_40_cluster(c_dataframe,c_train,1,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156520, 3)\n",
      "1720\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster2_frame=days_40_cluster(c_dataframe,c_train,2,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25844, 3)\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster3_frame=days_40_cluster(c_dataframe,c_train,3,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 3)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster4_frame=days_40_cluster(c_dataframe,c_train,4,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8463, 3)\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster5_frame=days_40_cluster(c_dataframe,c_train,5,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3640, 3)\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster6_frame=days_40_cluster(c_dataframe,c_train,6,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster7_frame=days_40_cluster(c_dataframe,c_train,7,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               51773        4668  11.091045\n",
      "2.0               14380        1575   9.130159\n",
      "3.0                3090         281  10.996441\n",
      "4.0                 125          11  11.363636\n",
      "5.0                1186          93  12.752688\n",
      "6.0                 394          40   9.850000\n",
      "7.0                  45           4  11.250000\n",
      "8.0               10322        1470   7.021769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "285.1578510229028"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_0.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               52082        4668  11.157241\n",
      "2.0               14565        1575   9.247619\n",
      "3.0                3034         281  10.797153\n",
      "4.0                 126          11  11.454545\n",
      "5.0                1271          93  13.666667\n",
      "6.0                 429          40  10.725000\n",
      "7.0                  35           4   8.750000\n",
      "8.0               10299        1470   7.006122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "286.0786605114055"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_1.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               51778        4668  11.092117\n",
      "2.0               14747        1575   9.363175\n",
      "3.0                3121         281  11.106762\n",
      "4.0                 120          11  10.909091\n",
      "5.0                1127          93  12.118280\n",
      "6.0                 400          40  10.000000\n",
      "7.0                  37           4   9.250000\n",
      "8.0               10273        1470   6.988435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "285.66238814376663"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_2.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               52003        4668  11.140317\n",
      "2.0               14665        1575   9.311111\n",
      "3.0                3053         281  10.864769\n",
      "4.0                 126          11  11.454545\n",
      "5.0                1299          93  13.967742\n",
      "6.0                 472          40  11.800000\n",
      "7.0                  40           4  10.000000\n",
      "8.0               10214        1470   6.948299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "286.1328362841287"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_3.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               52280        4668  11.199657\n",
      "2.0               14735        1575   9.355556\n",
      "3.0                3024         281  10.761566\n",
      "4.0                 122          11  11.090909\n",
      "5.0                1137          93  12.225806\n",
      "6.0                 442          40  11.050000\n",
      "7.0                  35           4   8.750000\n",
      "8.0               10187        1470   6.929932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "286.29006269865533"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_4.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Windowing with clusters (Lag=10, Day_of_theweek, holiday, company_offers, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster7=pd.read_csv('clust_7.csv') #cluster number\n",
    "data_cluster=pd.read_csv('data_clustering_R') #dataset used for clustering\n",
    "data_cluster['clust_7']=cluster7['x'] #joining the clusters\n",
    "data_cluster=data_cluster[['key','clust_7']]\n",
    "d1 = date(2017, 10, 1)  # start date\n",
    "d2 = date(2017, 12, 31)  # end date\n",
    "d3=date(2018, 1, 31)\n",
    "delta = d2 - d1         # timedelta\n",
    "\n",
    "pre_day=[]\n",
    "for i in range(delta.days + 1):\n",
    "    add=str(d1 + timedelta(days=i))\n",
    "    pre_day.append(add)\n",
    "\n",
    "post_day=[] \n",
    "delta_2 = d3 - d2\n",
    "\n",
    "for i in range(delta_2.days + 1):\n",
    "    add=str(d2 + timedelta(days=i))\n",
    "    post_day.append(add)\n",
    "df_days_pre = pd.DataFrame({'date':pre_day})\n",
    "df_days_post = pd.DataFrame({'date':post_day})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1166984, 35)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>rrp</th>\n",
       "      <th>new size_L</th>\n",
       "      <th>new size_M</th>\n",
       "      <th>new size_S</th>\n",
       "      <th>...</th>\n",
       "      <th>new size_44</th>\n",
       "      <th>new size_43</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>median_temp</th>\n",
       "      <th>company_offer</th>\n",
       "      <th>holiday</th>\n",
       "      <th>sum_unit</th>\n",
       "      <th>price_daily_change</th>\n",
       "      <th>new_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5625</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.3125</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.1875</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7500</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>190.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.7500</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           key  weekday  day  month        date     rrp  \\\n",
       "0           0  19671 39 1/3        6    1     10  2017-10-01  190.43   \n",
       "1           1  19671 39 1/3        0    2     10  2017-10-02  190.43   \n",
       "2           2  19671 39 1/3        1    3     10  2017-10-03  190.43   \n",
       "3           3  19671 39 1/3        2    4     10  2017-10-04  190.43   \n",
       "4           4  19671 39 1/3        3    5     10  2017-10-05  190.43   \n",
       "\n",
       "   new size_L  new size_M  new size_S     ...       new size_44  new size_43  \\\n",
       "0           0           0           0     ...                 0            0   \n",
       "1           0           0           0     ...                 0            0   \n",
       "2           0           0           0     ...                 0            0   \n",
       "3           0           0           0     ...                 0            0   \n",
       "4           0           0           0     ...                 0            0   \n",
       "\n",
       "   units  avg_temp  median_temp  company_offer  holiday  sum_unit  \\\n",
       "0    0.0   12.5625        12.50              0        0       0.0   \n",
       "1    0.0   13.3125        13.75              0        0       0.0   \n",
       "2    0.0   12.1875        12.50              0        1       0.0   \n",
       "3    0.0   10.7500        10.75              0        0       0.0   \n",
       "4    1.0   11.7500        11.50              0        0       1.0   \n",
       "\n",
       "   price_daily_change  new_product  \n",
       "0                 0.0            0  \n",
       "1                 0.0            0  \n",
       "2                 0.0            0  \n",
       "3                 0.0            0  \n",
       "4                 0.0            0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=train_df[['date','median_temp','weekday','holiday','company_offer','key','units']]\n",
    "#train['date']=train['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>median_temp</th>\n",
       "      <th>weekday</th>\n",
       "      <th>holiday</th>\n",
       "      <th>company_offer</th>\n",
       "      <th>key</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>12.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>12.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>10.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>11.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  median_temp  weekday  holiday  company_offer           key  \\\n",
       "0  2017-10-01        12.50        6        0              0  19671 39 1/3   \n",
       "1  2017-10-02        13.75        0        0              0  19671 39 1/3   \n",
       "2  2017-10-03        12.50        1        1              0  19671 39 1/3   \n",
       "3  2017-10-04        10.75        2        0              0  19671 39 1/3   \n",
       "4  2017-10-05        11.50        3        0              0  19671 39 1/3   \n",
       "\n",
       "   units  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    1.0  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=post_day[1:]\n",
    "col.append('key')\n",
    "all_=train.key.unique()\n",
    "empty_matrix=np.zeros((len(all_),len(col)))\n",
    "data_frame=pd.DataFrame(data=empty_matrix, columns=col)\n",
    "data_frame['key']=all_\n",
    "days=range(1,32)\n",
    "n1=len(days)\n",
    "empty_matrix_2=np.zeros((all_.shape[0],1))\n",
    "data_frame_2=pd.DataFrame(data=empty_matrix_2, columns=['key'])\n",
    "data_frame_2['key']=all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_prev=train.loc[train['date']=='2017-12-31'].sort_values('date')[['key','units']]\n",
    "sales_prev1=train.loc[train['date']=='2017-12-30'].sort_values('date')[['key','units']]\n",
    "sales_prev2=train.loc[train['date']=='2017-12-29'].sort_values('date')[['key','units']]\n",
    "sales_prev3=train.loc[train['date']=='2017-12-28'].sort_values('date')[['key','units']]\n",
    "sales_prev4=train.loc[train['date']=='2017-12-27'].sort_values('date')[['key','units']]\n",
    "sales_prev5=train.loc[train['date']=='2017-12-26'].sort_values('date')[['key','units']]\n",
    "sales_prev6=train.loc[train['date']=='2017-12-25'].sort_values('date')[['key','units']]\n",
    "sales_prev7=train.loc[train['date']=='2017-12-24'].sort_values('date')[['key','units']]\n",
    "sales_prev8=train.loc[train['date']=='2017-12-23'].sort_values('date')[['key','units']]\n",
    "sales_prev9=train.loc[train['date']=='2017-12-22'].sort_values('date')[['key','units']]\n",
    "sales_prev10=train.loc[train['date']=='2017-12-21'].sort_values('date')[['key','units']]\n",
    "sales_prev11=train.loc[train['date']=='2017-12-20'].sort_values('date')[['key','units']]\n",
    "sales_prev12=train.loc[train['date']=='2017-12-19'].sort_values('date')[['key','units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.merge(sales_prev, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-31'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev1, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-30'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev2, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-29'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev3, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-28'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev4, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-27'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev5, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-26'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev6, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-25'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev7, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-24'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev8, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-23'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev9, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-22'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev10, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-21'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev11, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-20'})\n",
    "data_frame_2=data_frame_2.merge(sales_prev12, left_on='key', right_on='key', how='left')\n",
    "data_frame_2=data_frame_2.rename(columns={'units':'2017-12-19'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame_2=data_frame_2.fillna(0)\n",
    "data_frame=pd.merge(data_frame,data_frame_2,on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train=train.merge(data_cluster,on='key',how='inner') #for traning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>median_temp</th>\n",
       "      <th>weekday</th>\n",
       "      <th>holiday</th>\n",
       "      <th>company_offer</th>\n",
       "      <th>key</th>\n",
       "      <th>units</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>12.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>12.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>10.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>11.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  median_temp  weekday  holiday  company_offer           key  \\\n",
       "0  2017-10-01        12.50        6        0              0  19671 39 1/3   \n",
       "1  2017-10-02        13.75        0        0              0  19671 39 1/3   \n",
       "2  2017-10-03        12.50        1        1              0  19671 39 1/3   \n",
       "3  2017-10-04        10.75        2        0              0  19671 39 1/3   \n",
       "4  2017-10-05        11.50        3        0              0  19671 39 1/3   \n",
       "\n",
       "   units  clust_7  \n",
       "0    0.0        1  \n",
       "1    0.0        1  \n",
       "2    0.0        1  \n",
       "3    0.0        1  \n",
       "4    1.0        1  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dataframe=data_frame.merge(data_cluster,on='key',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2018-01-02</th>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>2018-01-06</th>\n",
       "      <th>2018-01-07</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>2018-01-09</th>\n",
       "      <th>2018-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <th>2017-12-25</th>\n",
       "      <th>2017-12-24</th>\n",
       "      <th>2017-12-23</th>\n",
       "      <th>2017-12-22</th>\n",
       "      <th>2017-12-21</th>\n",
       "      <th>2017-12-20</th>\n",
       "      <th>2017-12-19</th>\n",
       "      <th>clust_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05  2018-01-06  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2018-01-07  2018-01-08  2018-01-09  2018-01-10   ...     2017-12-27  \\\n",
       "0         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "1         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "2         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "3         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "4         0.0         0.0         0.0         0.0   ...            0.0   \n",
       "\n",
       "   2017-12-26  2017-12-25  2017-12-24  2017-12-23  2017-12-22  2017-12-21  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2017-12-20  2017-12-19  clust_7  \n",
       "0         0.0         0.0        1  \n",
       "1         0.0         0.0        1  \n",
       "2         2.0         0.0        1  \n",
       "3         0.0         0.0        1  \n",
       "4         0.0         0.0        2  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_dataframe.head() #this is going to be used for predictive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather Data Preperation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_train=train[['date','median_temp']]\n",
    "weather_train=weather_train.drop_duplicates()\n",
    "weather_train=weather_train.sort_values('date')\n",
    "weather_train=weather_train.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_test=test_df[['date','median_temp']]\n",
    "weather_test=weather_test.drop_duplicates()\n",
    "weather_test=weather_test.sort_values('date')\n",
    "weather_test=weather_test.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_weather=weather_train.append(weather_test).set_index('date').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day of the week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_week_train=train[['date','weekday']]\n",
    "day_week_train=day_week_train.drop_duplicates()\n",
    "day_week_train=day_week_train.sort_values('date')\n",
    "day_week_train=day_week_train.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_week_test=test_df[['date','weekday']]\n",
    "day_week_test=day_week_test.drop_duplicates()\n",
    "day_week_test=day_week_test.sort_values('date')\n",
    "day_week_test=day_week_test.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_day_week=day_week_train.append(day_week_test).set_index('date').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holiday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holi_train=train[['date','holiday']]\n",
    "holi_train=holi_train.drop_duplicates()\n",
    "holi_train=holi_train.sort_values('date')\n",
    "holi_train=holi_train.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holi_test=test_df[['date','holiday']]\n",
    "holi_test=holi_test.drop_duplicates()\n",
    "holi_test=holi_test.sort_values('date')\n",
    "holi_test=holi_test.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_holiday=holi_train.append(holi_test).set_index('date').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Company Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co_train=train[['date','company_offer']]\n",
    "co_train=co_train.drop_duplicates()\n",
    "co_train=co_train.sort_values('date')\n",
    "co_train=co_train.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co_test=test_df[['date','company_offer']]\n",
    "co_test=co_test.drop_duplicates()\n",
    "co_test=co_test.sort_values('date')\n",
    "co_test=co_test.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_co=co_train.append(co_test).set_index('date').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the clusters\n",
    "def days_10_cluster_var(c_dataframe,c_train,clusterno,model):\n",
    "    c_train_c1=c_train[c_train['clust_7']==clusterno].drop('clust_7',axis=1)\n",
    "    all_=c_train_c1.key.unique()\n",
    "    n=len(c_train_c1.key.unique())\n",
    "    i=0\n",
    "    k=0\n",
    "    n1=len(pre_day)\n",
    "    days=[]\n",
    "    ids=[]\n",
    "\n",
    "    while(i<n):\n",
    "        b=all_[i]\n",
    "        k=0\n",
    "        while(k<n1):\n",
    "            a=pre_day[k] #day\n",
    "            ids.append(b) #id\n",
    "            days.append(a)\n",
    "            k=k+1\n",
    "        i=i+1\n",
    "        \n",
    "    train_days = pd.DataFrame({'date':days,'key':ids})\n",
    "    train_comb=train_days.merge(c_train_c1[['date','key','units']],on=['date','key'],how='outer')\n",
    "    train_comb=train_comb.fillna(0)\n",
    "    print(train_comb.shape)\n",
    "    print(len(all_))\n",
    "    print(n1)\n",
    "    print(n1*len(all_))\n",
    "    \n",
    "    train_comb_pivot=train_comb.pivot(index='key', columns='date', values='units')\n",
    "    train_comb_pivot=train_comb_pivot.mean(axis=0)\n",
    "    train_comb_pivot=train_comb_pivot.drop(['2017-11-24'])\n",
    "    train_comb_pivot=pd.DataFrame(train_comb_pivot,columns=['mean_sales'])\n",
    "    train_comb_pivot['temp']=weather_train['median_temp'].values\n",
    "    train_comb_pivot['week_day']=day_week_train['weekday'].values\n",
    "    train_comb_pivot['company_offers']=co_train['company_offer'].values\n",
    "    train_comb_pivot['holiday']=holi_train['holiday'].values\n",
    "    \n",
    "    train_cluster1=series_to_supervised(train_comb_pivot, n_in=10, n_out=1, dropnan=True) #mean_sales,temp,week_day,company_offers,holiday\n",
    "    \n",
    "    cluster1=c_dataframe[c_dataframe['clust_7']==clusterno]\n",
    "    cluster1_n=cluster1.drop('clust_7',axis=1).set_index('key').transpose()\n",
    "    cluster1.mean=cluster1_n.mean(axis=1)\n",
    "    cluster1_frame=pd.DataFrame(cluster1.mean, columns=['mean_sales'])\n",
    "    cluster1_frame=cluster1_frame.transpose() #where the predictive data will be written\n",
    "    \n",
    "    model.fit(train_cluster1[['var1(t-10)', 'var2(t-10)', 'var3(t-10)', 'var4(t-10)',\n",
    "       'var5(t-10)', 'var1(t-9)', 'var2(t-9)', 'var3(t-9)', 'var4(t-9)',\n",
    "       'var5(t-9)', 'var1(t-8)', 'var2(t-8)', 'var3(t-8)', 'var4(t-8)',\n",
    "       'var5(t-8)', 'var1(t-7)', 'var2(t-7)', 'var3(t-7)', 'var4(t-7)',\n",
    "       'var5(t-7)', 'var1(t-6)', 'var2(t-6)', 'var3(t-6)', 'var4(t-6)',\n",
    "       'var5(t-6)', 'var1(t-5)', 'var2(t-5)', 'var3(t-5)', 'var4(t-5)',\n",
    "       'var5(t-5)', 'var1(t-4)', 'var2(t-4)', 'var3(t-4)', 'var4(t-4)',\n",
    "       'var5(t-4)', 'var1(t-3)', 'var2(t-3)', 'var3(t-3)', 'var4(t-3)',\n",
    "       'var5(t-3)', 'var1(t-2)', 'var2(t-2)', 'var3(t-2)', 'var4(t-2)',\n",
    "       'var5(t-2)', 'var1(t-1)', 'var2(t-1)', 'var3(t-1)', 'var4(t-1)',\n",
    "       'var5(t-1)']],train_cluster1[['var1(t)']])\n",
    "    \n",
    "    days=range(1,32)\n",
    "    n1=len(days)\n",
    "    k=0\n",
    "    day_n=0\n",
    "    while(k<n1):\n",
    "        day=days[day_n]\n",
    "        predicted_date=datetime.date(year=2018,day=day,month=1)\n",
    "        pred_date_before=predicted_date- timedelta(days=10)\n",
    "        delta = predicted_date - pred_date_before\n",
    "        bet_day=[]\n",
    "        for i in range(delta.days):\n",
    "            add=str(pred_date_before + timedelta(days=i))\n",
    "            bet_day.append(add)\n",
    "        pred_date_before=str(pred_date_before)\n",
    "        predicted_date=str(predicted_date)\n",
    "        value_predict=pd.DataFrame([cluster1_frame[bet_day[0]].values, all_weather[bet_day[0]].values,all_day_week[bet_day[0]].values,all_holiday[bet_day[0]].values, all_co[bet_day[0]].values,\n",
    "        cluster1_frame[bet_day[1]].values, all_weather[bet_day[1]].values,all_day_week[bet_day[1]].values,all_holiday[bet_day[1]].values, all_co[bet_day[1]].values,\n",
    "        cluster1_frame[bet_day[2]].values, all_weather[bet_day[2]].values,all_day_week[bet_day[2]].values,all_holiday[bet_day[2]].values, all_co[bet_day[2]].values,\n",
    "        cluster1_frame[bet_day[3]].values, all_weather[bet_day[3]].values,all_day_week[bet_day[3]].values,all_holiday[bet_day[3]].values, all_co[bet_day[3]].values,\n",
    "        cluster1_frame[bet_day[4]].values, all_weather[bet_day[4]].values,all_day_week[bet_day[4]].values,all_holiday[bet_day[4]].values, all_co[bet_day[4]].values,\n",
    "        cluster1_frame[bet_day[5]].values, all_weather[bet_day[5]].values,all_day_week[bet_day[5]].values,all_holiday[bet_day[5]].values, all_co[bet_day[5]].values,\n",
    "        cluster1_frame[bet_day[6]].values, all_weather[bet_day[6]].values,all_day_week[bet_day[6]].values,all_holiday[bet_day[6]].values, all_co[bet_day[6]].values,\n",
    "        cluster1_frame[bet_day[7]].values, all_weather[bet_day[7]].values,all_day_week[bet_day[7]].values,all_holiday[bet_day[7]].values, all_co[bet_day[7]].values,\n",
    "        cluster1_frame[bet_day[8]].values, all_weather[bet_day[8]].values,all_day_week[bet_day[8]].values,all_holiday[bet_day[8]].values, all_co[bet_day[8]].values,\n",
    "        cluster1_frame[bet_day[9]].values, all_weather[bet_day[9]].values,all_day_week[bet_day[9]].values,all_holiday[bet_day[9]].values, all_co[bet_day[9]].values])\n",
    "        value_predict=value_predict.transpose()\n",
    "        y_pred=model.predict(value_predict)\n",
    "        cluster1_frame[predicted_date]=y_pred\n",
    "        k=k+1\n",
    "        day_n=day_n+1\n",
    "    \n",
    "    return(cluster1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(814936, 3)\n",
      "8858\n",
      "92\n",
      "814936\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster1_frame=days_10_cluster_var(c_dataframe,c_train,1,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158240, 3)\n",
      "1720\n",
      "92\n",
      "158240\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster2_frame=days_10_cluster_var(c_dataframe,c_train,2,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26128, 3)\n",
      "284\n",
      "92\n",
      "26128\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster3_frame=days_10_cluster_var(c_dataframe,c_train,3,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1012, 3)\n",
      "11\n",
      "92\n",
      "1012\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster4_frame=days_10_cluster_var(c_dataframe,c_train,4,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8556, 3)\n",
      "93\n",
      "92\n",
      "8556\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster5_frame=days_10_cluster_var(c_dataframe,c_train,5,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3680, 3)\n",
      "40\n",
      "92\n",
      "3680\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster6_frame=days_10_cluster_var(c_dataframe,c_train,6,regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 3)\n",
      "4\n",
      "92\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "cluster7_frame=days_10_cluster_var(c_dataframe,c_train,7,regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               43237        4668   9.262425\n",
      "2.0               15142        1575   9.613968\n",
      "3.0                2342         281   8.334520\n",
      "4.0                 120          11  10.909091\n",
      "5.0                 601          93   6.462366\n",
      "6.0                 251          40   6.275000\n",
      "7.0                  14           4   3.500000\n",
      "8.0               10322        1470   7.021769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "268.382190169169"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_0.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               42834        4668   9.176093\n",
      "2.0               15360        1575   9.752381\n",
      "3.0                2254         281   8.021352\n",
      "4.0                 122          11  11.090909\n",
      "5.0                 550          93   5.913978\n",
      "6.0                 232          40   5.800000\n",
      "7.0                  23           4   5.750000\n",
      "8.0               10299        1470   7.006122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "267.7200029881966"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_1.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               43036        4668   9.219366\n",
      "2.0               15496        1575   9.838730\n",
      "3.0                2381         281   8.473310\n",
      "4.0                 117          11  10.636364\n",
      "5.0                 569          93   6.118280\n",
      "6.0                 220          40   5.500000\n",
      "7.0                  25           4   6.250000\n",
      "8.0               10273        1470   6.988435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "268.5460854304155"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_2.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               42529        4668   9.110754\n",
      "2.0               15379        1575   9.764444\n",
      "3.0                2309         281   8.217082\n",
      "4.0                 124          11  11.272727\n",
      "5.0                 530          93   5.698925\n",
      "6.0                 244          40   6.100000\n",
      "7.0                  20           4   5.000000\n",
      "8.0               10214        1470   6.948299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "267.11233591880404"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_3.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correct_differ  clust_size       mean\n",
      "clust_7                                       \n",
      "1.0               43022        4668   9.216367\n",
      "2.0               15439        1575   9.802540\n",
      "3.0                2279         281   8.110320\n",
      "4.0                 119          11  10.818182\n",
      "5.0                 584          93   6.279570\n",
      "6.0                 232          40   5.800000\n",
      "7.0                  28           4   7.000000\n",
      "8.0               10187        1470   6.929932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "268.12310605391696"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test_4.csv')\n",
    "cluster_performance_measurement(test_data,cluster1_frame,cluster2_frame,cluster3_frame,cluster4_frame,cluster5_frame,cluster6_frame,cluster7_frame,data_cluster,'2018-01-22')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
