{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling_on 6 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('ARIMA_predict.csv')\n",
    "data1=pd.read_csv('Windowing_predict.csv')\n",
    "data2=pd.read_csv('GBoostRegression_predict.csv')\n",
    "data3=pd.read_csv('XGBoostRegression_predict.csv')\n",
    "data4=pd.read_csv('CombineModel_predict1.csv')\n",
    "data5=pd.read_csv('CombineModel_predict2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.rename(columns={'pre_units': 'pre_units1'})\n",
    "data1 = data1.rename(columns={'pre_units': 'pre_units2'})\n",
    "data2 = data2.rename(columns={'pre_units': 'pre_units3'})\n",
    "data3 = data3.rename(columns={'pre_units': 'pre_units4'})\n",
    "data4 = data4.rename(columns={'pre_units': 'pre_units5'})\n",
    "data5 = data5.rename(columns={'pre_units': 'pre_units6'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data.drop(['Unnamed: 0','units'],axis=1)\n",
    "data1=data1.drop(['Unnamed: 0'],axis=1)\n",
    "data2=data2.drop(['Unnamed: 0','date','units'],axis=1)\n",
    "data3=data3.drop(['Unnamed: 0','date','units'],axis=1)\n",
    "data4=data4.drop(['Unnamed: 0','units'],axis=1)\n",
    "data5=data5.drop(['Unnamed: 0','units','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.merge(data1,data,how='left',left_on=['key','day'], right_on = ['key','day'])\n",
    "train_data1=pd.merge(train_data,data2,how='left',left_on=['key','day'],right_on = ['key','day'])\n",
    "train_data2=pd.merge(train_data1,data3,how='left',left_on=['key','day'], right_on = ['key','day'])\n",
    "train_data3=pd.merge(train_data2,data4,how='left',left_on=['key','day'], right_on = ['key','day'])\n",
    "train_data4=pd.merge(train_data3,data5,how='left',left_on=['key','day'], right_on = ['key','day'])\n",
    "train_data=train_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>day</th>\n",
       "      <th>units</th>\n",
       "      <th>pre_units2</th>\n",
       "      <th>pre_units1</th>\n",
       "      <th>pre_units3</th>\n",
       "      <th>pre_units4</th>\n",
       "      <th>pre_units5</th>\n",
       "      <th>pre_units6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032266</td>\n",
       "      <td>0.082668</td>\n",
       "      <td>0.02940</td>\n",
       "      <td>0.01844</td>\n",
       "      <td>0.082668</td>\n",
       "      <td>0.082668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034279</td>\n",
       "      <td>0.079272</td>\n",
       "      <td>0.03128</td>\n",
       "      <td>0.02018</td>\n",
       "      <td>0.079272</td>\n",
       "      <td>0.079272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037971</td>\n",
       "      <td>0.076319</td>\n",
       "      <td>0.02303</td>\n",
       "      <td>0.01262</td>\n",
       "      <td>0.076319</td>\n",
       "      <td>0.076319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036492</td>\n",
       "      <td>0.073751</td>\n",
       "      <td>0.02303</td>\n",
       "      <td>0.03937</td>\n",
       "      <td>0.073751</td>\n",
       "      <td>0.073751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19671 39 1/3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>0.071518</td>\n",
       "      <td>0.02303</td>\n",
       "      <td>0.01634</td>\n",
       "      <td>0.071518</td>\n",
       "      <td>0.071518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  day  units  pre_units2  pre_units1  pre_units3  pre_units4  \\\n",
       "0  19671 39 1/3    1    0.0    0.032266    0.082668     0.02940     0.01844   \n",
       "1  19671 39 1/3    2    0.0    0.034279    0.079272     0.03128     0.02018   \n",
       "2  19671 39 1/3    3    0.0    0.037971    0.076319     0.02303     0.01262   \n",
       "3  19671 39 1/3    4    0.0    0.036492    0.073751     0.02303     0.03937   \n",
       "4  19671 39 1/3    5    0.0    0.040193    0.071518     0.02303     0.01634   \n",
       "\n",
       "   pre_units5  pre_units6  \n",
       "0    0.082668    0.082668  \n",
       "1    0.079272    0.079272  \n",
       "2    0.076319    0.076319  \n",
       "3    0.073751    0.073751  \n",
       "4    0.071518    0.071518  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensembling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaqian/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/xiaqian/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(colsample_bytree=0.7,learning_rate=0.03,n_estimators=1000,max_depth=6,min_child_weight=7,objective='reg:linear',subsample=0.7)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "target_prediction = cross_val_predict(model, train_data.drop(['units','key','day'],axis=1), train_data[['units']], cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_prediction1=pd.DataFrame(target_prediction, columns=['pre_units']).round(decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_need=train_data[['key','day','units']]\n",
    "df_prediction_need=df_prediction_need.reset_index(drop=True)\n",
    "pre_total=df_prediction_need.merge(df_prediction1, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397544, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def predict_date(pre_total):\n",
    "    date=[]\n",
    "    i=0\n",
    "    n=len(pre_total)\n",
    "    while i<n:\n",
    "        day_int=pre_total.iloc[i]['day']\n",
    "        date_time=datetime.datetime(2018, 1, day_int, 0,0).date()\n",
    "        date_string=str(date_time)\n",
    "        date.append(date_string)\n",
    "        i+=1\n",
    "    pre_total['date']=date\n",
    "\n",
    "    pre_total_pvt = pre_total.pivot_table('pre_units', ['key'], 'date')\n",
    "    pre_total_pvt['key'] = pre_total_pvt.index\n",
    "    pre_total_pvt=pre_total_pvt.reset_index(drop=True)\n",
    "\n",
    "    return pre_total_pvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_total_pvt= predict_date(pre_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import math\n",
    "\n",
    "def measurement(prediction, test_data):\n",
    "\n",
    "    d1 = date(2018, 1, 1)  \n",
    "    d2 = date(2018, 1, 31)  \n",
    "    delta = d2 - d1         \n",
    "    pre_day=[]\n",
    "    for i in range(delta.days + 1):\n",
    "        add=str(d1 + timedelta(days=i))\n",
    "        pre_day.append(add)\n",
    "\n",
    "    sold_out_day=[]\n",
    "    key=[]\n",
    "    #lets innet join with testdataset\n",
    "    window_inner=test_data.merge(prediction,left_on='key', right_on='key', how='inner')\n",
    "    window_inner['sol_out_pred']=0\n",
    "\n",
    "    all_=window_inner.key.unique()\n",
    "    n=len(all_) \n",
    "    i=0\n",
    "\n",
    "    while(i<n): #dataset\n",
    "        subset_w=prediction.loc[prediction['key']==all_[i]]\n",
    "        stock=test_data.loc[test_data['key']==all_[i]]['stock'].values[0]\n",
    "        n1=len(pre_day)\n",
    "        k=0\n",
    "        while(k<n1): #day calculation\n",
    "            day=pre_day[k]\n",
    "            that_day_sale=subset_w[day].values[0]\n",
    "            stock=stock-that_day_sale\n",
    "            if((stock==0) | (stock<0) ):\n",
    "                window_inner.iloc[i,37]=day\n",
    "                break\n",
    "            if(k==(n1-1)): \n",
    "                window_inner.iloc[i,37]='2018-01-22'\n",
    "            k=k+1\n",
    "        i=i+1\n",
    "\n",
    "    test_data['key']=test_data[\"pid\"].astype(str) +\" \"+ test_data[\"size\"].astype(str)\n",
    "    window_inner[\"date_sold_out_date\"] = pd.to_datetime(window_inner[\"sold_out_date\"],format=\"%Y/%m/%d\")\n",
    "    window_inner[\"date_sold_out_pred\"] = pd.to_datetime(window_inner[\"sol_out_pred\"],format=\"%Y/%m/%d\")\n",
    "\n",
    "    days_differ=window_inner[\"date_sold_out_date\"]-window_inner[\"date_sold_out_pred\"]\n",
    "    days=pd.DataFrame(days_differ,columns=['days_differ'])\n",
    "    days['correct_differ']=abs(days['days_differ'].astype(datetime.timedelta).map(lambda x: np.nan if pd.isnull(x) else x.days))\n",
    "\n",
    "    error=math.sqrt(sum(days['correct_differ']))\n",
    "\n",
    "    return error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(test_table,total):\n",
    "    \n",
    "    test_data_0=pd.read_csv(test_table)\n",
    "    test_data_0['pid']=test_data_0['pid'].astype(int)\n",
    "    test_data_0['key']=test_data_0[\"pid\"].astype(str) +\" \"+ test_data_0[\"size\"].astype(str)\n",
    "\n",
    "    error_total=measurement(total, test_data_0)\n",
    "\n",
    "    print('\\ntotoal',error_total)\n",
    "    \n",
    "    return error_total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "totoal 252.01984048879962\n"
     ]
    }
   ],
   "source": [
    "error_0=error('test_0.csv',pre_total_pvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "totoal 253.4896447589132\n"
     ]
    }
   ],
   "source": [
    "error_1=error('test_1.csv',pre_total_pvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "totoal 253.7715508089904\n"
     ]
    }
   ],
   "source": [
    "error_2=error('test_2.csv',pre_total_pvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "totoal 253.11459855172322\n"
     ]
    }
   ],
   "source": [
    "error_3=error('test_3.csv',pre_total_pvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "totoal 253.0375466210499\n"
     ]
    }
   ],
   "source": [
    "error_4=error('test_4.csv',pre_total_pvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253.086636246\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "total=[error_0,error_1,error_2,error_3,error_4]\n",
    "\n",
    "print(numpy.mean(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
